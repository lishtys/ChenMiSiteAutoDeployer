{"pages":[{"title":"","text":"google-site-verification: google7b16f38938435373.html","link":"/google7b16f38938435373.html"},{"title":"Tags","text":"","link":"/tags/index.html"},{"title":"Categories","text":"","link":"/categories/index.html"},{"title":"All","text":"","link":"/portfolio/index.html"},{"title":"Commercial","text":"","link":"/portfolio/Commercial.html"},{"title":"Projects","text":"Here listed my open source projects.","link":"/projects/index.html"},{"title":"Unity Hotfix Solution (xLua, AssetBundle) - xLua","text":"SummaryIn this post, we will start to add xLua into our project and show how to use inside your project and interact with gameobjects. Introduction Installation Loader Lua Table, Run Lua Function Hotfix Lower Level Changes Survival Shooter Example IntroductionxLua is a framework adding Lua scripting capability to Unity. At beginning, it is internal solution in Tencent. Now it is public on Github and maintained by Tencent. It has full English documents and tutorial in the Repo. It has been used in many commercial games, which proves its stability. Installation Unpack the zip package. Drag [xLua] folder , [Plugin] folder into your project. After compiling, you can see [Xlua] menu item at the topbar. Quick Start To Use Lua Run CSharp Code 1LuaEnv.DoString(&quot;CS.UnityEngine.Debug.Log(&apos;hello world&apos;)&quot;); DoString parameter is a string, and you can enter any allowable Lua code. A LuaEnv instance is virtual machine to run the commands. Better to be unique globally. CS means CSharp, to access any functions or content inside a class, use full namespace path and add ‘CS.’ at the beginning. LoaderBy default, you can use following Lua function run Lua scripts: 1&quot;require &apos;luaVariableExample&apos;&quot; To call the lua function, like quick start, 1LuaEnv.DoString(&quot;require &apos;luaVariableExample&apos;&quot;); This is default loader in xLua. It will automatically look for [‘xxxx’.lua.txt] file inside [Resources] folder. Then run content inside the file. For instance, in Assets/Resources/luaExample.lua.txt 1print(\"Function From luaExample.txt\"); After calling DoString function, it will print txt in the console. [It’s Lua print funtion, not Unity Debug function] Customize LoaderUse LuaEnv.AddLoader. It takes delegate in wich defines how to access lua files. For example, I want to load Lua files from SteamingAssets folder not Resources file. 1234private byte[] RealLoader(ref string filePath) { return Encoding.UTF8.GetBytes(File.ReadAllText(Application.streamingAssetsPath + &quot;/_Assets/_Lua/&quot; + filePath + &quot;.lua.txt&quot;)); } After using env.AddLoader(RealLoader); to add your loader into the virtual maching. The require 'luaExample' scripts would first look file inside [StreamingAssets/_Assets/_Lua/]. If there is no file named LuaExample.lua.txt, it will continue looking inside [Resources] folder. Get Table Values, Run FunctionsAssuming we have lua file called luaVariableExample.lua.txt inside Resources folder. 1234567891011121314151617ID=1001221001Name=&quot;Chen Mi&quot;Male= trueMeshData= { position=&quot;1,2,1&quot;, scale=&quot;1&quot;,}function Test() print(&quot;This is Test Function!&quot;)endfunction Test1(a,b) print(a+b)end In order to get these values, you can use env.Global.Get&lt;T&gt;(&quot;KeyName&quot;). It also supports struct. 1234567891011121314 var id= env.Global.Get&lt;int&gt;(\"ID\"); var name= env.Global.Get&lt;string&gt;(\"Name\"); Debug.Log(\" Global Variable ID is \"+id+\" - Name is \"+name); var md= env.Global.Get&lt;MeshData&gt;(\"MeshData\"); Debug.Log(md.position+ md.scale); //..... public class MeshData{ public string position; public int scale;} For functions, it supports using delegates. You need to declare delegates first and give it an attribute [CSharpCallLua] 12[CSharpCallLua]delegate void TestFunction(int a, int b); Then you can call the lua function like below : 12LuaFunction lFunc = env.Global.Get&lt;LuaFunction&gt;(&quot;Test1&quot;);lFunc.Call(112, 1); It would give you a result 113. HotfixProject Setup Add the HOTFIX_ENABLE macro to enable this feature (to File-&gt;Build Setting-&gt;Scripting Define Symbols in Unity). Execute the XLua/Generate Code menu. Generating Wrapper. [In Editor] Execute the “XLua/Hotfix Inject In Editor” menu when developing a hotfix in the editor. WorkflowTaskWe need to overwrite Spawn() in [“Survival Shooter”] 123456789101112131415161718192021222324namespace CompleteProject{public class EnemyManager : MonoBehaviour{ void Start () { InvokeRepeating (&quot;Spawn&quot;, spawnTime, spawnTime); } void Spawn () { if(playerHealth.currentHealth &lt;= 0f) { return; } int spawnPointIndex = Random.Range (0, spawnPoints.Length); Instantiate (enemy, spawnPoints[spawnPointIndex].position, spawnPoints[spawnPointIndex].rotation); }}} Setup Give Class an Attribute [Hotfix]. In our case 12345namespace CompleteProject{ [Hotfix] public class EnemyManager : MonoBehaviour //... Give Method an Attribute [LuaCallCSharp]. In our case 123456//.... [LuaCallCSharp] void Spawn() {//.... } Run [Project Setup] step 2,3. Write Lua scripts. Use xlua.hotfix([ClassName],[FunctionName],[NewLuaFunction]).In our case 1xlua.hotfix(CS.CompleteProject.EnemyManager,&apos;Spawn&apos;,[NewLuaFunction]) Following Lua script just replace the original implementation into [Print Log]. 12345xlua.hotfix(CS.CompleteProject.EnemyManager,'Spawn',function(self)print('LOL')end) If you need to access private variables in the class from Lua function, you need to use xlua.private_accessible([ClassName]). In our case 1xlua.private_accessible(CS.CompleteProject.EnemyManager) Below is the Lua function for Spawning the enemies. 123456789101112131415xlua.private_accessible(CS.CompleteProject.EnemyManager)xlua.hotfix(CS.CompleteProject.EnemyManager,&apos;Spawn&apos;,function(self)if self.playerHealth.currentHealth&gt;50 then self.spawnTime = 1endmytable = {self.spawnPoints}local spawnIdx= CS.UnityEngine.Random.Range (0, #mytable)spawnIdx=math.floor(spawnIdx)CS.UnityEngine.GameObject.Instantiate (self.enemy, self.spawnPoints[spawnIdx].position, self.spawnPoints[spawnIdx].rotation);end) Low LevelAccording to the author, Before hotfix 1234567public class Calc{ int Add(int a, int b) { return a + b }} After hotfix, in IL, it will add codes like this: 123456789public class Calc{ static Func&lt;object, int, int, int&gt; hotfix_Add = null; int Add(int a, int b) { if (hotfix_Add != null) return hotfix_Add(this, a, b); return a + b }} When Lua calls the hotfix, the hotfix_Add will point to a reference (function). If there is no hotfix for this function, it will add a if statement.","link":"/portfolio/Pili_Incredible.html"},{"title":"All","text":"","link":"/works/index.html"},{"title":"About Me","text":"","link":"/profile/index.html"},{"title":"Commercial","text":"","link":"/works/Commercial.html"},{"title":"Resume","text":"","link":"/resume/index.html"}],"posts":[{"title":"Entertainment Arts Engineering U 2017 Fall","text":"Entertainment Arts &amp; Engineering 有4个Track, 除了项目课程外，游戏设计课是必修课，由 Game 和 Play 两部分组成，分别由两个老师负责各部分内容。整个大班拆成两个 小班，学期中期互相替换老师上不同的部分。 这门课不局限于视频游戏，以探讨游戏本身的娱乐玩法为核心，José P的部分基本上会有一小时课堂玩各种游戏，扑克、色子、桌游等等。Ashley 的部分随机分小组，在课程的部分时间里完成一些小任务。 每个星期老师会布置下次上课相关的话题文档，一次大约六十到一百多页，阅读完成之后再写一份类似读后感的文章为作业的一份，额外会有与话题的其他作业，比如Game Design Document 需要分析街机游戏和手机游戏的系统结构和玩法结构。这门课充当的角色更像是给游戏设计一个范畴，抛砖引玉，引导思考。这门课的考核是设计一个赌博游戏，在最后一节课上开庄，赢钱最多的组为优胜组。（不禁止作弊，嗨的一批） 从课程涉及的话题内容和提供的学习文档内容来说，这些的确是国内相关（卖狗肉）的专业不会涉及到的。电子游戏的发展历史以及人文的因素提供了相关研究发展的环境，在这边确实有很多从非技术的角度去分析研究的文献，当真正的把游戏当作一种艺术来看待时，如何回归到游戏本身的功能而不是设计成长曲线（挖坑）应当是制作游戏优先考虑的内容。 Rapid Prototype这门课让我魂不守舍彻夜难眠，让我感激当年核皇的不杀之恩，让我一直怀疑这门课就是用来折腾Engineers的。 这门课一星期上两次，同样由两个老师一起指导，一个给糖一个扇巴掌。形式更像是松散的工作室管理模式，一般是两到三周做出一个游戏，实际除去第一天分组，讨论做啥，最后一节课做展示和周末，实际开发时间只有两周。（最短的一个项目实际开发周期只有七天，微笑） 每次换新主题的游戏会重新随机分组，指定游戏引擎。第一个问Ryan的问题 : -“ Can i use Unity? ” - “You can have a dream.” 大部分Producer没有实际工作经验，导致了最开始初生牛犊不怕虎，第一个项目用Mono Game 几乎是做了五个不同的游戏，最后一次修改（新游戏）离最后展示不到30个小时，微笑。 你见过在一个方法里连续写了六行一样的代码的程序员吗？ 你见过因为不知道如何在Phaser里切分不同类文件就把整个游戏写在一个文件里2000多行代码的程序员吗？ 你见过还有十个小时就展示代码写不出来回家然后差点和朋友闹崩的程序员吗？ 你见过叫你爹的程序员吗？ 微笑。 在最后一个项目里，俩老师突然宣布所有项目组的TA都被自己项目组开除（强行被开除），然后他们自己成立了新项目组，然而对于当时我的项目组就是瞬间爆炸，只剩下Engineer x1 + TA x1 + Prod x1， 当时还强行边学Unreal边用蓝图连节点，这辈子再也不想用蓝图做任何数组循环条件判断的事情了。 这门课除了在实践中积累经验（其实对于有实际项目开发经验的人来说，这块内容几乎可以忽略），最重要的就是大概确定大家的符文系统和技能天赋，Quick Dating. C++ For Game老师很壮，壮到我感觉他能一拳打死我。他的车很骚气，是个小跑车，反正外形骚气的一批。车的牌号屌炸天，Unreal。 这门课并不是教C++的课，需要有一定的C++功底上。同时这门课也是为了接下来三个学期的游戏引擎课做基础。 学海无涯苦作舟。 视频链接","link":"/2017 Fall/"},{"title":"归国前后（一）— GDC大会","text":"var ap = new APlayer({ element: document.getElementById(\"aplayer-GxTKPdQg\"), narrow: false, autoplay: false, showlrc: false, music: { title: \"爱即正义\", author: \"三无MarBlue\", url: \"https://chenmi-ink-1252570167.cos.na-siliconvalley.myqcloud.com/Music/%E7%88%B1%E5%8D%B3%E6%AD%A3%E4%B9%89.mp3\", pic: \"https://p1.music.126.net/NMEHvq2CgiM4nL2ShxtF0g==/109951162930971961.jpg\", lrc: \"\" } }); window.aplayers || (window.aplayers = []); window.aplayers.push(ap); 三月中旬系里组织去了一趟GDC，在旧金山待一星期，省钱图方便，就在市政府北边定了一个旅店。 Game Developers Conference周日上午走在附近的街道，随处可见流浪汉，还有流着不明液体的街道，和码头那块游客区差别还是挺大的。 跟着Tony和肆爷在码头吃了顿好的，享受。 从码头回来，Uber司机说，下午六点半之后就别步行出门了。 后来发现，到了傍晚确实有点乱，一次下雨回来的时候，在旅馆楼梯口饮料机旁边睡着一个小哥；某个晚上某汉在二楼走廊上唱了一晚上歌。 说正事。 乐元素GDC之前在Linkedin和乐元素的小姐姐联系上了，在旧金山有幸与CEO王海宁、CTO凌聪见了面， 听了他们的发家史和对游戏产业相关的看法。听“过来人”的经历总是能从中了解/悟出一些东西。说的糙点，正如一年前临行时候写的，刚到少年时代听着大佬们胡侃吹逼都觉着了不起。 之后小姐姐到了盐湖城，一起吃了个晚饭。有句话一直没对你说，嗯，谢谢，请多来几次。 五月回国，之前公司的大佬还在打趣，王海宁（王总）依旧是低调。 深以为然。 NYU CMU USC RIT展会期间跟着肆爷恬不知耻的认识了几个浙大的同学，又在北美留学生交流会上见到了大四实习认识的网友，正儿八经的网友见面。 说起来，或许留美读研学游戏设计，最最开始还真是莫名从群里加上了，然后问了些Unity的事情，最后决定直接拿DirectX折腾的这位学姐。 在乐元素上认识了个CMU的小哥哥，也是一身强运，拿到了当天唯一一个微软送的XBox。（我撞见了之后，告诉他那边有抽奖活动，这样的话，我算不算是个挖井人呢？） 互相吐槽，大约都有种，你们专业比我们的好多了，这课才是真硬核。 NYU的作品集很棒，个人单干出游戏，学科的安排压力很大，然后EAE的课程.. Emmmm…. 从本校，其他的学校学长学姐得知，留在美国做游戏，似乎比起传统CS专业更难些。 听说CMU ETC留下来的，大多不在做游戏了。Emmm….. Unity TechnologyGDC 第一天晚上靠嘴皮子，临时搞到名额，带着肆爷混入了Unity官方的一个Party，欸，这才知道什么叫酒水免费，餐饮免费。 发布会坐我旁边的是易车网全球副总裁，一个大光头，在收到GDC第一张名片后，互相吹捧一波，然后会上一直拍视频，说是要成立VR团队balabala… 好像是周三，反正有一天，三餐都是在Unity那解决的。 午餐的时候，Will就坐在旁边，按耐不住内心激动，腆着脸皮尬聊之后果断要求合照，美滋滋，心满意足。 毕竟，机缘巧合下能进入到游戏行业，也是因为接触到了Unity呀。 游戏与人工智能这次GDC大会给AI专门划分了Summit，里面涉及到很多机器学习的内容，趋势上，感觉很多公司都在将机器学习与游戏制作相结合，提供更优质更高效的用户体验。 无论是三消类游戏的关卡难度判断，还是针对用户行为做出的产品消费精准投放，都可以借助机器学习和人工智能相关技术。 问过Nick为什么不做机器学习来学游戏，他回答说，做机器学习要等很久才能出结果，做的过程中也不知道结果是对是错是不是想要的；所以觉着做游戏会更好玩些。 虽然没做过机器学习相关的内容，但这话，应该靠谱。游戏人做游戏，理所当然，天经地义。 地平线的寻路&amp;动画技术宣讲给我的感觉是——MMP，怪不得这游戏这么好玩。 刺客信条·起源的任务系统宣讲给我的感觉是——他在讲什么，这口浓厚的法语腔调的英文，真的听不懂。 末尾盐湖城是摩门教的势力区，摩门教不喝含咖啡因兴奋类的饮料，UU校区内也是禁酒的。有几位同学在Airbnb的房主说，在盐湖城没怎么喝酒吧，过去带他们喝酒。 班上的男生就说一到旧金山就要抽大麻，要看脱衣舞，反正大麻是真的臭。 这一趟最重要的，是接触了来自各个学校、已工作未工作的学长学姐朋友大佬们，交流分享、诚恳建议都来之不易，感谢。 在旧金山最后一天，吴伯伯带着我们玩了一圈。 感谢。 GDC之后到回国这段时间，都和实习有关，放在下一章写把。","link":"/2018 GDC/"},{"title":"归国前后（二）— 实习前奏","text":"暑期实习美国这边的游戏行业整体技术结构和目前国内的情况相差还是挺大的。 国内使用Unity引擎做游戏开发的团队从数量上还是占优势，包括腾讯网易内部的项目组也有不少用Unity开发，如果不是一心向扎AAA游戏，一开始靠Unity倒是不愁找工作的事情。 美国这边比较简单，不管如何先来一两套Coding，其它之后再说。 难度基本上是Leetcode Medium 之上。 GDC期间网友学姐和传说钟董晶辉学长（反正你也这么出名了）聊着，说是美国这边对游戏初级从业者不是很友好，入门的技术曲线相对Flag公司较高些。 大体感受也是如此，CS公司主要把Leetcode刷好，找工作就不难了。 也就是美国游戏行业面试还有那些后续诸如其他的东西，涉及图形学，游戏引擎，某些特定的引擎，当然跑不开C++。 上一届反馈里也听说过，中国学生先后投同一家公司，只是把名字换成美国风格的名字，第二次就接到了电话。 Emmmm…. 也有一个传奇的学长，去年靠着喝酒拿下了实习，期间什么技术都没聊，一身强运。 等到五月底回国和毕业的学长学姐聊，感觉去向还是比较随心随意的，虽然道阻且长，但终究是可行之路。 有志者，事竟成。 一面腾讯去GDC之前接到腾讯某个工作室的电面，约着GDC结束后周日晚上。 面试大约持续了40-50分钟，问的偏理论和底层，可能这也和组长是做游戏引擎出身相关。 比如动画Blend是如何做权重的，FBX中如何存储动画信息的，基本上说到哪问到哪，能一直问到说不出那种。 最简单的应该A*寻路算法怎么实现的。 后来得到消息，进了，让我们多考虑一阵子。后来听说是之前有接了Offer没去的情况，作为公司肯定不希望浪费资源，这点很理解。 然后考虑了一阵子回复后，组内只申请到社招名额。 这次面试经历收获不小，扭正了些认知偏差，也下定决心要做出一些改变和突破。 感谢两位学长。 GApp Lab GluGDC期间在Unity Connection 大会上认识了Glu的技术招聘主管，会点中文，且用微信。 互相吹捧一番后，问了些求职准备的事情。 暑期实习名额相对来说没有那么多，加之SLC也不像NYC,SFO那么方便。 四月初腾讯事情得到结果之后，学期也快结尾了，申请了GApp Lab，做医疗教育相关的Serious Game或者App。 也进了，暑期一共招了三个大陆学生。 接了Offer后就计划回国呆上个十来天。 网易邀请在考虑第一个腾讯Offer时候，接到了网易游戏邮件，没有要求笔试，直接说简历过了，后续会有相关人员联系我。 那段时间正好是第五人格出来，处理 Behaviour 和 绝地求生 版权的事情。 后来和一位去了完美的前同事聊了会儿，似乎当时又撞上了阿里整组整组的挖人。 想来应该是在GDC上认识一位雷火策划大佬，周老师，说他们就用Unity，缺程序呀。 当我屁颠屁颠拿出倩女幽魂录说这个游戏有一阵子玩了挺久，那位大佬说，这游戏我们都认为是个失败品，不行不行。 2333，幸好没说我还冲了终身会员。 不过当时听闻这个游戏在越南那边发行的，最近上了游戏，还活着。 后来排队看到雷霆的老大，或者老大之一，一头白发，拿了个吃鸡类型带moba技能的卡渲风格的游戏展示玩了玩，说是暑期要上线。 回国后，才接到了网易后续邮件，说是加微信聊聊。 那会儿已经被腾讯光子录取，在和GApp Lab争取，礼貌回了邮件。 之后，应该是让我们江湖再见吧。 二面腾讯还有一周就要从国内飞回美国，挑了个时间回师大转了转，正巧学院拍毕业照，碰上了院长大人，聊了会之后中午约了个饭。 再去学院里见导师的时候，又碰上了龚老师，正巧大学那几年他外派国外做研究，一直只见其名不见其人，被逮住了，那大家一起在食堂吃了个饭。 真巧这会儿光子工作室的HR小姐姐加了微信，问什么时候方便面试。 因为晚上要坐高铁，就说周末或者周一都可以。 于是第二天周六刚刚睡醒，有点懵的情况下就接到了第一通电话，问了些数据结构算法和游戏开发相关的问题，大概聊了下原来的工作经验，就说马上会有二面。 过了几分钟，第二通电话过来，非技术面，聊了些想法什么的，之后就说没问题，可以准备过来了。项目对内高度保密，那会儿也不知道是什么类型，只是确定Unity。 心动。 之后联系GApp Lab，因为距离实习开始只剩下五天，Lab回邮件的时候用上了Careful、Hard的词，虽然说会尝试找Engineer替代，但只有几天，不能保证，感觉有些不高兴。 之前招进去的三个大陆学生，两位同学临时该变主意，再强辞一波感觉会对以后招中国学生有影响。 直到最后一周得到回复，思前想去，这样的情况，撂摊子良心有点过不去，几经波折还是到了GApp Lab。 这或许是国内国外暑期实习时间不同步的缘故。 接到录取通知的邮件，想哭。 六月左右得到消息，知道了是个超大IP的游戏，心疼自己。 由己及人，待人待己总是顺从本心。 抱歉，HR小姐姐，明年请一定叫我。 结尾实习找工作面试，这段经历对我来说挺有意思的，本科的时候错过了所有校园实习，也没有学长学姐的提点。 以至于毕业后七月份去4399面试，面试人问我，为什么不在校园招聘的时候来？ 现在只有社招岗。 我说，我不知道有这个事儿。 下一章是这次回国的经历，之后还有一章，写写回到SLC的事情。","link":"/2018 Internship/"},{"title":"EAE 6320 Engineering II - 01 Project Setup","text":"This is the first assignment of the semester, which requires us set up the project and modify the engine instead of actually creating features. The main purpose of the assignment is to learn how to set up the solution, which involves platform specific code, reference list, project dependencies and use of DLL libraries. There are several important points you may need to know: Click Download download the game. Key Points Exclude platform specific files by adding exclusion rules to correspond files. In this assignment, the x64 platform should not compile OpenGL codes so make exclusion rules for those files in graphic project. Use property sheets to manage projects. The sheets order would cause different effects and by setting Marcos. This is a solid and convenient way to handle different types of project location. Reference &amp; Dependency is important for linking projects. You should only contain necessary references instead of adding all of other projects. In this assignment,although [Graphics] project has headers form [Asserts] , [Time] class and use namespaces from [Results] and [Math] project, there is no use case or function calls in the project. Similarly, [ShaderBuilder] project contains Graphics namespace but not call any function. Don’t need to add these references. In my case, Encrypted For Now . Question For John-Paul Here I don’t understand why we don’t add a dependency of [BuildAssets] project to the [Game] Project. In my opinion, if we add the reference, the compile &amp; build flow would work solidly and automatically by one click. It helps make the flow faster and prevent from forgetting to update assets. Goods The way to generate different shaders for OpenGL and DirectX in one project is convenient and useful. I am a big fan of auto pipeline, which I think would help improve the whole workflow. While working in a game company, I build an auto art assets importer pipeline for the project. It will import FBX files and generate prefabs, attach scripts, make animation clips and create correspond animatosr with customized animation phases. ProcessThe assignment took me 10 hours to finish, including reading instructions, linking projects, optional challenges and write-ups. The way that set up a single project for loading dynamic DLL and use properties to include the files is elegant. While setting up projects, I forgot to modify the value of Force Include property. By reading error messages, at first I think it is a reference loss of OpenGL project that causes the problem. I move constant buffer block from four shader into one single .inc file to reduce redeclaration of these properties. This file works as a template to generate shader files. PersonalizeControlsHold [SPACE] key to slow down the color animation. You may see slower animation transition like the images below. (When it becomes dark, it become slower than usual). Output Implementation In application Updates function, I add codes listening to user inputs. When pressing down the [SPACE] key, it will set the simulate time factor to 0.5f, which makes the animation slow. After releasing the [SPACE] key, it will set simulate time factor back to 1. In shaders, I use cos() &amp; sin() to change values in red channel and blue channel. To soften the color value and animation, the calculation value is scaled by ½, add ½. A hint form Implementation of Half Lambert For an instance, the red curve shows y=cos(x) and the blue curve shows y=.5 * cos(x)+0.5 . The curve becomes smoother after recaculation. ExpectationI focused on C# and Unity development before attending EAE. Since this course is mostly about C++ and graphics rendering, I felt a little worry about this course during the summer. Now that after finishing the first assignment, I got excited about what I have learned and achieved during this assignment. Now I’m looking forward to learning more about rendering and C++. For future topics, specifically form what I learn from Interviews with Tencent, these topics would be good to know and have a practice in graphics area: Self-defined FBX data structure, support skin animation. Animation Blender. Q-Tree or Octree - brief implementation DownloadClick Download download the game. Version: x64 - DirectX.","link":"/EAE 6320 Assignment 01/"},{"title":"EAE 6320 Engineering II -  03 Further Graphic Independent","text":"Continue with platform independent task from last week, this time I remove the Graphics.[platform].cpp making united interfaces for both OpenGL and DirectX. Also, I modify the implantations for cMesh &amp; cEffects, which allows users to pass data rather than hard coded. The mesh data format used in cMesh has been changed to vertices array with index array. Click Download download the game. ProcessIn last post, I add a cMeshData class. Since the sMesh would be extended in the future, I remove the MeshData first. GraphicsBaseThen in order to remove Graphics.[Platform].cpp files, I make a new namespace [GraphicsBase] to handle platform dependent codes and a Graphics.cpp to keep the original interfaces and calls for the graphic render pipeline. In this way, the Graphic.cpp would be clean. [GraphicsBase] file is in the Graphics project. Below are interfaces: 1234567{ void ClearTarget(Graphics::Color c); cResult CleanUp(); cResult Initialize(const Graphics::sInitializationParameters&amp; i_initializationParameters); void Swap();} The Initialize() handles DirectX specific view initialization and Swap() deal with both platform buffer swapping. ClearTarget() takes a Color class to change the back buffer color. By using the color class, it allows user to define different color they want. It has a default color set black. Below is a usage in Graphic.cpp Defination12Color();Color(float r, float g, float b, float a); Usage12345 { // Clear Color Graphics::Color c; GraphicsBase::ClearTarget(c);} cMeshIn order to support creating multiple meshes and save memory space. The cMesh has a new interface to setup geometry data : 123 cResult InitializeGeometry(std::vector&lt;VertexFormats::sMesh&gt; veticesArray, std::vector&lt;uint16_t&gt; indexArray); It takes vertices data and index data, which could allow the engine only keep unique vertices and use index sequence to combine the vertices. In the project, I decide to use DirectX winding order as default. The InitializeGeometry() would take care of differences. As a result, the Graphics.cpp only need to care one copy of geometry data. (In OpenGL, I directly reverse index array. It’s better to use a copy to keep the index array clean in general cases. – Okay for temporary stage. ) usage in graphics.cpp 123456789//..// datastd::vector&lt;Graphics::VertexFormats::sMesh&gt; meshes(vData, vData + vertexCount);std::vector&lt;uint16_t&gt; indexArray(iData, iData + indexCount);//..if (!(result = s_mesh_instance.InitializeGeometry(meshes, indexArray))) { //... } In the future, those meshes and index data are stored in a file like fbx. Right now it’s fine to hard code as an input from outside. cEffectThe changes on cEffect are quite simple. Just let shader file paths become parameters that can be changed by users. 123 ceae6320::cResult InitializeShadingData(const char filePath[], const char filePath2[]); usage in graphics.cpp 123456789101112131415// Initialize the shading data{ if (!(result = s_effect_instance.InitializeShadingData( \"data/Shaders/Vertex/standard.shader\", \"data/Shaders/Fragment/tintColorAnimation.shader\"))) { //... } if (!(result = s_effect_instance1.InitializeShadingData( \"data/Shaders/Vertex/standard.shader\", \"data/Shaders/Fragment/standard.shader\"))) { //... }} Memory UsagecMesh Platform Geometry Data Index Length Extra Alignment Total OpenGL 3 GLuint 1 uint16 Yes 16 bytes DirectX 3 Pointer 1 uint16 Yes 32 bytes cEffect Platform Handler Render State ProgramId Extra Alignment Total OpenGL 2 1 1 GLuint Yes 16 bytes DirectX 2 1 NULL No 40 bytes Render State Platform Struct Data Extra Alignment Total OpenGL 1uint8 Yes 1 bytes DirectX 3 Pointer + 1uint8 Yes 32 bytes Note: DirectX is x64 platform, which takes 8 bytes for each address. OpenGL is x86 platform, which takes 4 bytes for each address. Note: The Handler is 4 bytes each. Thoughts &amp; Discussion Lots of implementation in cMesh follows the fact that both platform would store vertex data and index data into buffer. In this case, we don’t need to store data in codes. In my opinion, current solution has sacrificed some flexibility (Maybe). If get rid of [index_Length], the cMesh would become smaller. Some misc infomation like index length could store in File Header. PersonalizeControlsHold [SPACE] key to slow down the color animation. You may see slower animation transition like the images below. (When it becomes dark, it become slower than usual). Output Implementation Back Buffer Color Animation 12345678auto stime= sin(s_dataBeingSubmittedByApplicationThread-&gt;constantData_perFrame.g_elapsedSecondCount_simulationTime);auto ctime= cos(s_dataBeingSubmittedByApplicationThread-&gt;constantData_perFrame.g_elapsedSecondCount_simulationTime); // Clear ColorGraphics::Color c(stime,ctime, stime + ctime,1);GraphicsBase::ClearTarget(c); In Fragment shader, I get vertex position and change color for each section: if(i_position.x&lt;256) rVal=rVal/2+0.5; if(i_position.y&lt;256) bVal =bVal/2+0.5; The picture contains 2 meshes. One is for 4 white triangles,which uses standard shader. The other is for the center square using animation shader. 12345678910111213141516171819202122 //...vData[1].x = 0.0f;vData[1].y = 0.5f;vData[1].z = 0.0f; //...vData[3].x = 0.5f;vData[3].y = 0.5f;vData[3].z = 0.0f;std::vector&lt;Graphics::VertexFormats::sMesh&gt; meshes(vData, vData + vertexCount);//...uint16_t iData[indexCount];iData[0] = 0;//..iData[5] = 2;std::vector&lt;uint16_t&gt; indexArray(iData, iData + indexCount); This assignment takes me 8 hours to finish. DownloadClick Download download the game. Version: x64 - DirectX.","link":"/EAE 6320 Part 03/"},{"title":"EAE 6320 Engineering II -  06  Assets Builder, External Mesh File, Handle, Lua","text":"In this assignment, we added external files which contains meshes information. We use Lua files as a formatted structure and use assets manager to track all the mesh handles instead of pointers. Points Since we just use files for temporary, we care more about the readability instead of efficiency this time. It’s easy to compress text content and convert to binary files. Use handles to track all instances usage. This is the way we load and bind shader to effects and it automatically loads data and initialize instance. This is an assets loader. Understand Lua stack and pop data from nested tables. Click Download the game. ProcessMeshFileFirst, I searched for STL model format. This format is quite simple and only contains vertex information. The ASCII STL is defined as below: 1234567facet normal ni nj nk outer loop vertex v1x v1y v1z vertex v2x v2y v2z vertex v3x v3y v3z endloopendfacet For readability. I’ve designed the mesh format like below: Cube: 12345678910111213141516171819202122232425262728293031return{ VerArray = { {-1.0,-1.0,1.0}, {-1.0,1.0,1.0}, {1.0,1.0,1.0}, {1.0,-1.0,1.0}, {-1.0,-1.0,-1.0}, {-1.0,1.0,-1.0}, {1.0,1.0,-1.0}, {1.0,-1.0,-1.0}, }, IndexArray = { {0,1,2}, {0,2,3}, {4,6,5}, {4,7,6}, {4,5,1}, {4,1,0}, {3,2,6}, {3,6,7}, {1,5,6}, {1,6,2}, {4,0,3}, {4,3,7}, },} In my opinion, we only need position information for current assignment. So we can just use position array like above. In common cases, people will recognize each section as x,y,z position. For index information, I divide elements into groups, this will help us see triangles. Since we always create and modify models in DDS applications like MAYA, we don’t really need to add more prefix or symbols to help user change the content. The file is assumed to be output from third application. MeshBuilderAfter having these files, we need to build them into assets. The MeshBuilder is responsible for the mesh data assets. Its current main job is to copy file into correct “Data” folder and works with BuildMyGameAssets project to set up configurations. In this case, we need to think more about the platform independent properties and dependency cMeshIn cMesh, I update its implementation of MeshFactory. Right now, it takes and return “Handle” reference. Factory1cResult MeshFactory(const char* const i_path, Handle &amp;mesh_handle) Load 123LoadAsset(const char* const i_path,std::vector&lt;Graphics::VertexFormats::sMesh &gt;&amp;i_mesh,std::vector&lt;uint16_t &gt;&amp;indexArray); cMesh doesn’t hold the Handle in the class, the loading job is done by cManager. Inside its loading function, it reads the Lua tables and make vertex std::vector and index std::vector to initialize the mesh render-able data. Handle The Handle works as file handle and prevent from reloading again. Still we need to update reference count. [location] If the handle is in the cGameObject, it suggests the handle is from file handle(combine with file source). -&gt; Not expected to change. If the mesh change frequently, it’s may be better to hold meshes in other places. PersonalizeControlsHold [SPACE] key to slow down the color animation. Hold [Shift] key to hide the square in the center. Hold [Ctrl] key to change four triangles color. Press [↑, ↓, ←, →] keys to move around camera. Press [Q],[E],[Z],[C] keys to rotate camera left, right, up and down. Press [A],[S],[D],[W] keys to move around default gameobject. Press [1],[2] keys to switch default gameobject’s mesh. [1] -&gt; Cube; [2] -&gt; Small Plane Screen Shots Download Click Download the game. Version: x64 - DirectX.","link":"/EAE 6320 Write-up 06/"},{"title":"EAE 6320 Engineering II -  04 Application, Graphics Threads","text":"Right now, all the rendering inputs are implemented within [Graphics] project, which belongs to engine module not game module. In real world, a game programmer would not directly write codes in engine project. In this case, this time, I move mesh, effect, color inputs into [MyGame] project. It involves dealing with data in two threads. One is rendering thread which is used for rendering cached data, the other is application thread which manages data in application. Click Download download the game. ProcessIn last post, the Graphics project becomes platform independent. It makes easier to move cMesh and cEffect to MyGame project. Since we decided to use two threads, it requires us to cache data rather than draw it immediately. In this case, we will submit all the data in Game project and store them in [s_dataBeingSubmittedByApplicationThread] and use reference counting to track their usages. Submit Render DataThe struct [sDataRequiredToRenderAFrame] is used to cache information rendered in a frame. Submit Background ColorFirst, I add a Color variable named backgroundColor. The variable would be assigned in [MyGame.cpp]. For the simulation time, I created a function in cAppliction.h which returns simulationSecoundCount. 12345678//Simulation Timeauto ctime= (float)cos(GetElapsedSecondCount_simulationTime());auto stime= (float)sin(GetElapsedSecondCount_simulationTime());//Submission of colorGraphics::Color c = Graphics::Color(ctime, stime, ctime+stime, 1.0f);Graphics::SubmitClearColor(c); Submit Mesh &amp; Effect PairsThen, I add two pointer arrays. One is used to keep meshes data, the other is to keep effects data. Besides, I add a uint16 variable to keep the mesh &amp; effect pairs length. The struct now like below:123456789struct sDataRequiredToRenderAFrame { //... eae6320::Graphics::Color backgroundColor; eae6320::Graphics::cMesh** meshArray; eae6320::Graphics::cEffect** effectArray; uint16_t i_meshSize; }; The instances of mesh and effects are created in Initializes function. In Game.cpp , I defined these instances like below:12eae6320::Graphics::cEffect *s_effect_instance1;eae6320::Graphics::cMesh *s_mesh_instance1; Since we added reference counting, users are not supposed manually create these instances directly. As a result, they could use functions to initialize its own data instead. cEffect instance usage in below: 123456if (!(result = Graphics::cEffect::EffectFactory(\"data/Shaders/Vertex/standard.shader\",\"data/Shaders/Fragment/standard.shader\",s_effect_instance1))) //.... Once we setup pairs data, users can submit them in MyGame.cpp :123456void cMyGame::SubmitDataToBeRendered(const float f1,const float f2){ //...Graphics::SubmitMeshEffectPairs(s_mesh_instance, s_effect_instance);} At first, It turns out messages says some assets still remains after closing the application. With Yuxian’s help, I realize I forget to clean up references of data in [Application] thread. Memory UsagecMesh Platform Geometry Data Index Length Reference Count Extra Alignment Total OpenGL 3 GLuint 1 uint16 1 uint16 No 16 bytes DirectX 3 Pointer 1 uint16 1 uint16 Yes 32 bytes cEffect Platform Handler Render State ProgramId Reference Count Extra Alignment Total OpenGL 2 1 1 GLuint 1 uint16 No 16 bytes DirectX 2 1 NULL 1 uint16 Yes 48 bytes Render State Platform Struct Data Extra Alignment Total OpenGL 1uint8 Yes 1 byte DirectX 3 Pointer + 1uint8 Yes 32 bytes DataRequiredToRenderAFrame Platform sPerFrame Color Pointer Arrays Length Extra Alignment Total OpenGL 1 4 floats 1 pMesh + 1 pEffect 1 uint16 Yes 172 byte DirectX 1 4 floats 1 pMesh + 1 pEffect 1 uint16 Yes 184 byte Note: DirectX is x64 platform, which takes 8 bytes for each address. OpenGL is x86 platform, which takes 4 bytes for each address.Note: The Handler is 4 bytes each.Note: The sPerFrame is 144 bytes.Note: The DataRequiredToRenderAFrame only contains pointer size. Combine mesh &amp; effect size manually. Thoughts &amp; Discussion We use two threads to separate logic and render tasks. This is helpful to deal with massive calculation of models, skin animations or particles. Reason to Cache Data Each render entity has two copies. The application and graphic threads update these two copies and sync at the end of a frame.In this case, storing data in place could avoid swapping data constantly, which could also improve the performance. PersonalizeControlsHold [SPACE] key to slow down the color animation. You may see slower animation transition like the images below. Hold [Shift] key to hide the square in the center. Hold [Ctrl] key to change four triangles color. Input Control Output Implementation In order to detect user input, I override the implantation of BaseOnSimulationInput. Use two boolean values to keep key states. To make auto animation, I override the implantation of UpdateSimulationBasedOnTime . Inside, it will switch value of a boolean value which controls the visibility of four small triangles. Below is the default sreenshot. DownloadClick Download download the game. Version: x64 - DirectX.","link":"/EAE 6320 Write-up 04/"},{"title":"EAE 6320 Engineering II -  09 Binary Effects, Shader Independent","text":"Last week, we have implemented binary mesh files that can be used in runtime. It’s more flexible and efficient than previous. This time, we need to make our effects driven by data. Points Design human readable file content &amp; format. Design binary format. Create Effect Builder to generate data files. Remove hard-code path, change implementation of old cEffects. Refine lua assets build work-flow. Click Download the game. ProcessEffectBuilderEffectBuilder is much like MeshBuilder. It extracts effects data from source path (human readable file) and convert data to binary files. We need three data to make a effect for gameobject. They are RenderState,Vertex Shader, Fragment Shader. Human Readable File I use three flags to define render states. If the flag is less or equals 0, it means corresponding status are disable. Whereas, the status is enable. Next is a path table, contains vertex shader file path and fragement shader path. Below is the content. effect data123456789return{ -- flag order --1.DepthBuffering 2.AlphaTransparency 3.DrawingBothTriangleSides renderState={1,0,0}, vfShaders={\"shaders/vertex/standard.shader\",\"shaders/fragment/tintcoloranimation.shader\"},} I make order comments as hints for easy use. Binary FileColorAnimation Effect Order Render Status. (Blue Rect) uint8 data Vertex shader file path length ( Orange Rect) uint16 data Vertex shader file path (Follow Orange Rect) string data Fragment shader file path (The Rest) string data Paths The path in binary file is a little different than human readable file. It contains &quot;data/&quot; at the beginning, which is added during building binary files. In this case, we don’t need to modify string in runtime, which saves much time especially when there are thousands of effects files. However, it also increase the storage space and make it less flexible if users want to put into other folders. Since this is a engine, adding some rules to achieve better performance is worthy. Load EffectIn cEffect, there is a factory function initializing effects data by shaders and render states. Since we have new effect system. I update the function interface that using effect file to do the same thing. 1cResult EffectFactory(const char filePath[],cEffect*&amp; c_effect) Below is the implementation of extracting data from binary files. Load Binary Asset12345678910111213141516171819202122232425//... //Load Binary Asset Platform::sDataFromFile pData; Platform::LoadBinaryFile(filePath, pData); uintptr_t start = reinterpret_cast&lt;uintptr_t&gt;(pData.data); uintptr_t current = start; uint8_t renderState = *reinterpret_cast&lt;uint8_t*&gt;(current); current += sizeof(uint8_t); uint16_t pathLen = *reinterpret_cast&lt;uint16_t*&gt;(current); current += sizeof(uint16_t); auto path = reinterpret_cast&lt;char*&gt;(current); current += sizeof(char)*(pathLen); auto path1 = reinterpret_cast&lt;char*&gt;(current); current += sizeof(char)*(pathLen);//... result = instance-&gt;InitializeShadingData(path, path1, renderState); //.... return result; AssetBuildFunctions.luaTo refine the building flow, we only build shaders that listed in effect files rather than converting all of them. To support this feature, we need to extract paths in lua and register them to be built afterwards. It involves adding new functions in building effect status. Shader Platform IndependentI follow D3D naming convention using precompiler to replace keywords and functions in OpenGL like below: 12#define float4x4 mat4#define float2 vec2 After using new keywords, all the codes in side main can be moved outside “Platform Specific”. The codes are like below:1234567891011121314{Platform Specific}#endif{ float4 vertexPosition_world; float4 vertexPosition_local = float4( i_vertexPosition_local, 1.0 ); vertexPosition_world = mul(g_transform_localToWorld, vertexPosition_local) ;//....} PersonalizeControlsHold [SPACE] key to slow down the color animation. Hold [Shift] key to hide the square in the center. Hold [Ctrl] key to change four triangles color. Press [↑, ↓, ←, →] keys to move around camera. Press [Q],[E],[Z],[C] keys to rotate camera left, right, up and down. Press [A],[S],[D],[W] keys to move around default gameobject. Press [1],[2] keys to switch default gameobject’s mesh. [1] -&gt; Teapot; [2] -&gt; Circle Screen Shots Download Click Download the game. Version: x64 - DirectX.","link":"/EAE 6320 Write-up 09/"},{"title":"EAE 6320 Engineering II -  07  Maya Mesh Exporter Plug-in","text":"In this assignment, I created a mesh exporter tools in Maya based on Jhon-Paul’s project. In addition, I added the color property into Graphic renderer. Points Create MayaMeshExporter project. Pay attention to the dependencies and debug in exporting. Take care of color render in different platforms and the limits of vertices based on our design. Updates Lua loader and keep readable for users. Click Download the game. ProcessMaya ExporterSince we have new file extention for the mesh, I update the file path loading .mesh files. Inside the file, I decided to export color property and add keyword to distinguish the POSITION and COLOR infomation inside the mesh. The exported mesh format is like below Plane.mesh123456789101112131415161718VerArray ={{position={-4.60451,-1.51643,4.7557},color={0.0904,0.0421,0.54,1},},{position={4.60451,-1.51643,4.7557},color={0.5331,0.54,0.0423,1},},{position={-4.60451,-0.24221,-4.7557},color={0.54,0.1462,0.0422,1},},{position={4.60451,-0.24221,-4.7557},color={0.0421,0.54,0.5271,1},}, Exporter DependencyBecause it’s an independent tool for art assests, I think we don’t need to add any dependency into the new exporter project. And I clean all the solution and only build the exporter project. It works. Have to change the access permission to complete the copy cmd. Vertices LimitsThis is pretty straitforward. Since we designed the index as a uint16, we can hold 2^16=65536 vertices. When starting loading lua files, check the number of vertices. If the number is greater than the max size, return fialed and give user hints. In order to give a friendly user experience, I created a default question mark mesh for replacing any wrong meshes. like below: Debugging in MayaIt’s super cool to know we can use Visual Studio to debug in Maya. Just attach any process in the computer. PersonalizeControlsHold [SPACE] key to slow down the color animation. Hold [Shift] key to hide the square in the center. Hold [Ctrl] key to change four triangles color. Press [↑, ↓, ←, →] keys to move around camera. Press [Q],[E],[Z],[C] keys to rotate camera left, right, up and down. Press [A],[S],[D],[W] keys to move around default gameobject. Press [1],[2] keys to switch default gameobject’s mesh. [1] -&gt; Cube; [2] -&gt; Small Plane Screen Shots Download Click Download the game. Version: x64 - DirectX.","link":"/EAE 6320 Write-up 07/"},{"title":"EAE 6320  -  Engine System Proposal","text":"General Functions Add animation system for gameobject. Add animation data builder. Implement basic animation blend flow for transitions. If Enough Time Add animation system for vertex - (treat as bone) Support animation states configs Tables Integrate FBX Parser into current mesh file information Process 11.07 - Finish GameObject Position Animation [hard code test case]. TODO: Rotation Animation; Document Writeup; 11.07 - Finish GameObject Rotation Animation [hard code test case – Quaternion Lerp may not sure]. TODO: Change to GameObjectAnimation &amp; Support multiple animation clips; 11.07 - Finish Multiple animation clips . TODO: Change to GameObjectAnimation &amp; AnimationBuilder; How To UseGameObject Animation Create cAnimation as a component to control the animation. Add duration and Keys into cAnimation. Use functions to play each animation. Config Tables Contains key frames data. Lua format in certain rules. (Human readable &amp; Binary) May consider compress the file data. Parser &amp; DataSince FBX is a standard binary format, maybe it’s possible to make a parser output data into current Maya Exported Data. Textures Extracting Textures directly from FBX and render it inside engine. Implementation First implement gameobject animation to control the position &amp; rotation. Design animations tables and states configuration tables; Store data in Lua and and converted into binary file. Implement playAnimation(string keyword) function in cAnimation functions and used in cGameObject. Get it rendered in Engine. Try Implement vertex animation work as ‘skeleton animation`. Ideally, use states table to define animation connections and use it to control transitions.","link":"/EAE 6320 Write-up 10/"},{"title":"EAE 6320  - Gameobject Animation System, Keyframes, Table","text":"Updates 11.07 - Finish GameObject Position Animation [hard code test case]. 11.07 - Finish GameObject Rotation Animation [hard code test case – Quaternion Lerp may not sure]. 11.07 - Finish Multiple animation clips . 11.07 - Add AnimationBuilder Project &amp; Designed Animation Lua table. Screen Shot Click Download the game. cAnimationGameObject AnimationFor now, the cAnimation system controls the position &amp; rotation of a whole gameobejct. It will override the position and rotation when it is playing, just like what Unity animation did. Therefore, next step is to change its name to cGameobjectAnimation. If the cGameobject support nested parent tree, like make one cGameobject as a child of cGameobject. It will would work like Unity way. Future Add vertex animation if everything goes well. Treat each vertex as joint? Basic ImplementationKeyFrame This is a data structure storing animation keyframe. It needs time and animation data. Like below: 123456struct KeyFrame { float time; Math::sVector position; Math::cQuaternion rotation; }; cAnimation It has Binds(cGameObject ),AddKey(index, time, pos, rotation), Updates(deltaTime)and several play, stop functions. For a cAnimation, it contains a list of animation clips. Each clip has a list of keyFrame. Below variables in cAnimation. 12345678910111213141516171819202122232425262728293031323334353637383940float duration; // Animation Timeint frame; // Current Framefloat time; // Current Timebool playing;bool looping;int currentClipIndex; // Current Playing Clip Index// Current Animate ObjectcGameObject* c_object_=nullptr;// Cached Animation KeyFramesstd::vector&lt;std::vector&lt;KeyFrame&gt;&gt; keyframesList;``` ***In `Update` function, it will calculate current `time` and update ` keyframe`. Then interpolate position and rotation.``` C++//....//Decide which is current frame //....float alpha = (time - keyframes[frame - 1].time) / (keyframes[frame].time - keyframes[frame - 1].time); auto pos = keyframes[frame - 1].position; auto posNext = keyframes[frame].position; Math::sVector animPos;// Learner Lerp Position animPos.x = pos.x + (posNext.x-pos.x )*alpha; animPos.y = pos.y + (posNext.y-pos.y )*alpha; animPos.z = pos.z + (posNext.z-pos.z )*alpha; c_object_-&gt;s_rigid_body_state.position=animPos; // Learner Lerp Rotation//..... Future Add more lerp curves. Make it configurable. cGameObject Test CodeCurrently, in cGameObject, after InitializingGeometry. I used below codes to define a animation like screen shot in [Output section]. 1234567891011121314151617181920212223242526//for animation test//Start &amp; End Data Math::cQuaternion rot; Math::sVector rotDir(0,1,0); Math::sVector pos; pos.x = 1.2f; pos.y = 0.0f; pos.z = -0.7f;//Initialize animation and make keyframes anim.duration = 10; anim.AddKey(0, 0.0f, pos,rot); anim.AddKey(0,2.0f, Math::sVector(1.2f,1.0f,-0.7f), Math::cQuaternion(90.0f, rotDir)); anim.AddKey(0, 5.0f, Math::sVector(1.2f, -1.0f, -0.7f), Math::cQuaternion(145.0f, rotDir)); anim.AddKey(0, 10.0f, pos, rot); //Bind Data and play anim.Binds(this); anim.loop(true); anim.play(); Changes &amp; Discussion To support rotation lerp, I add Math function and operator for cQuaternion. I think this is just tiny changes. If I want to add “Vertex Animation”, I may need to store “Vertex Array Data” somewhere. This may increase memory usage in cMesh or cGameObject. Probably, I would divide animation system into two projects. One deals with gameobject animation. One handles vertex animation if I implement. I may check to see the difference between sLerp and Lerp. Currently for the rotation, I just use simple Lerp. At least in test codes, it looks fine. Animation TableStore a list of clips and each clip has a list of keyframe and its duration. So I made a nested tables like below and put clip duration into other tables. [Haven’t done testing. May Change.] 1234567891011121314151617181920212223242526272829303132333435return{Clips={{-- 1st Animation Clip {time=0,position={1.2,0.0,-0.7},rotation={0,0,1,0},},-- .... },{ -- 2nd Animation Clip {time=0,position={1.2,0.0,-0.7},rotation={0,0,1,0},},-- ....},},Duration={10,20}} PersonalizeControlsHold [SPACE] key to slow down the color animation. Hold [Shift] key to hide the square in the center. Hold [Ctrl] key to change four triangles color. Press [↑, ↓, ←, →] keys to move around camera. Press [Q],[E],[Z],[C] keys to rotate camera left, right, up and down. Press [A],[S],[D],[W] keys to move around default gameobject. Press [1],[2] keys to switch default gameobject’s mesh. [1] -&gt; Teapot; [2] -&gt; Circle Screen Shots Download Click Download the game. Version: x64 - DirectX.","link":"/EAE 6320 Write-up 11/"},{"title":"EAE 6320  - Multiple Animation Clips, Binary","text":"Updates 11.13 - Finish AnimationBuilder. 11.13 - Finish animation table binary loader test. 11.14 - Change interfaces for multiple animation . 11.14 - Complete file loading aniamtion test. Screen Shot cAnimationMultiple Aniamtion ClipsBecause of multiple animation clips, I update cGameObjectAnimation adding list of duration and animations. 12345// Cached Animation KeyFramesstd::vector&lt;std::vector&lt;KeyFrame&gt;&gt; keyframesList;//Cached Durations for each clipstd::vector&lt;float&gt; durationList; Animation TableThe main strcture has no change. For a better human readable format, just swicth the order, here is the nested table structure. Duration List Clip List -&gt; KeyFrames -&gt; KeyFrame -&gt; {Time, Pos, Rotation} Below is an example (2 clips with 4 key frames each): 1234567891011121314151617181920212223242526272829303132333435363738394041return{Duration={10.0,20.0},Clips={ { -- Clip - 1 { kTime=0.0, position={1.2,0.0,0.7}, rotation={1,0,0,0}, }, { -- keyframe 2 }, { -- keyframe 3 }, { -- keyframe 4 }, }, { -- Clip - 2 { -- keyframe 0 }, { kTime=8.0, position={1.2,1.0,0.7}, rotation={-0.707,0,-0.707,0}, }, { -- keyframe 2 }, { -- keyframe 4 }, },},} Explanation kTime : the time of the keyframe. You should keep it starts from 0 and ends at the duration for correct display. rotation: currently it stores data in Quaternion. I may make a Vector-&gt;Quaternion function for a better use. Animation BuilderIt’s like other Builder projects under Tools folder. To use that, you need to add types in AssetsToBuild and add functions like before, write binary files into Data. Binary DataThe Order Clips Count - uint16_t Time Array (in seconds) - Float Array ==Loop for Clips Count== Keys Count - uint16_t KeyFrame Array - KeyFrame ==End== cGameObjectInitializeRight now, in LoadRenderInfo, it pass the cGameobjectAnimation to the gameobject. Inside, it binds the animation and play it as default. UsesIn cMyGame, put all animation instances inside the Update(seconds) function and update them. In cGameObjectAnimation, it provides public functions to stop or swicth animations. Discussion &amp; Plan I’m thinking of adding File Handler for cGameObjectAnimation. But it may takes lots of work not on the feature itself. I’d rather refine some implementation and add small features like transitions, time control. Move current cGameObjectAnimation into an independent project. Update cGameobject and cGameobejctAnimation animation functions for a more flexible control. Start to make some efforts on vertex animation if time is allowed. PersonalizeControlsHold [SPACE] key to slow down the color animation. Hold [Shift] key to hide the square in the center. Hold [Ctrl] key to change four triangles color. Press [↑, ↓, ←, →] keys to move around camera. Press [Q],[E],[Z],[C] keys to rotate camera left, right, up and down. Press [A],[S],[D],[W] keys to move around default gameobject. Press [1],[2] keys to switch default gameobject’s mesh. [1] -&gt; Teapot; [2] -&gt; Circle Screen Shots Download Click Download the game. Version: x64 - DirectX.","link":"/EAE 6320 Write-up 12/"},{"title":"EAE 6320  - Final Project Proposal - 3D Flappy Bird.","text":"SummaryFor the final project, I’m planning to make a 3D flappy bird style game. This was the first game I made when i was learning Unity. Since the project support 3D meshes and no texture, the project is 3D based. Features A Character moving horizontally. Random generated obstacles along the road. - Different types of obstacles. Collectable Items. (If time is enough, it may include special items other than coin) Obstacle will have colliders, by default, when character hit the obstacle, the game is over. Objects may have its own animations. It will have sounds when trigger certain events. Animation Engine Feature Add a [local space] animation that doesn’t overwrite gameobject world position. Add some animation clips for obstacles and collectable items. Audio Engine Feature When changing character movement, it will play sound. When Hitting Obstacles, it will play sound. When collect items , it will play sound. Audio System LinkClick Shantanu’s Blog for audio system’s detail.","link":"/EAE 6320 Write-up 14/"},{"title":"EAE 6320  - Final Project - 3D Flappy Bird.","text":"SummaryDuring this semester, we’ve built a game engine based on John-Paul’s architecture and add our own sub system into the engine. For the final project, I’ve made a 3D Flappy Bird based on the project and subsystem we made – Animation &amp; Audio. GameGameplayThe game play is quite simple. Use keyboard move up the bird, prevent it from hitting the pipes. While flying, the bird can catch the coins. Once it collides with obstacles, it fails and player can restart the game. Screenshot ControlsPress [ENTER] key to start &amp; restart the game. Press [SPACE] key to push up bird. Press [←, →] keys to move around camera. Key Process Made meshes in Maya. Add Audio System from Shantanu’s project. Add [Additive Animation] for my Animation System. Add AABB collision detection into the project. Using object pool implement infinitely scrolling module. System &amp; ImplementationFeatures Use File Handler maintain meshes and effects. Although the game has lots of pipes and coins, it only needs one pipe mesh and one gold mesh. File Handler Use binary file to read &amp; store data. Binary Mesh Use multi-threads to handle physic calculation and graphic rendering. Multi-Threads Use keyframe animation system work with rigid body movement. Sub-Animation System Platform independent support. Issues While using Audio System, for some reason, it does not work for playing one shot without having set up a loop sound first; The sound play function and stop function does not work properly with each other. May create several sound instances and cause crash Download Click Download the game. Version: x64 - DirectX.","link":"/EAE 6320 Write-up 15/"},{"title":"EAE 6900 Realtime Rendering - Render Command","text":"SummaryThis writeup is a review of adding render commands into current engine project. Currently the project would submit mesh &amp; effect to graphic render moudle. The render binds effects and draw meshes one by one from input arrays. Usually in a game, it would have many mesh instance sharing same effects. If we use current solution dealing with rendering, it will bind same effects several times and render same meshes several times, which is a waste of resources. For better performance, we want to find a solution which can group up all the mesh instances. In this case, renderer can skip unneccesary steps. However, in order to implement this feature, we need to use more memeroy to store extra mesh information. Here is our solution. Render CommandRather than directly drawing all the data, we use a unit64_t number to store mesh&amp;effect pair meta information and use them sort meshes. Generally speaking, we store effects index, mesh index, depth index and other render data into the command. Because it is a unit64_t value, it is easy for computer to sort them. Then, we simply add some logic to handle same effects and mesh instances. Layout 57 - 64 -&gt; Effect Handle Index 47 - 56 -&gt; Depth Value 9 - 16 -&gt; Mesh Handle Index 1 - 8 -&gt; Array Index (Use this index to get the mesh data such as transforms) ResultScreenShot You can see meshes are rendered first by effects group and then by distance. GPU Capture 7 draw calls (Blue); 2 effect changes (Red) 2 vertex and index buffers (Green) 1 per-frame data (Gold) MoreWe can encode Render State and Shader into render cmd to get a better performance. PersonalizeControlsHold [SPACE] key to slow down the color animation. Hold [Shift] key to hide the square in the center. Hold [Ctrl] key to change four triangles color. Press [↑, ↓, ←, →] keys to move around camera. Press [Q],[E],[Z],[C] keys to rotate camera left, right, up and down. Press [A],[S],[D],[W] keys to move around default gameobject. Download Click Download the game. Version: x64 - DirectX.","link":"/EAE 6900 Realtime Rendering  01/"},{"title":"EAE 6900 Realtime Rendering - Shader & Transforms","text":"SummaryThis writeup is a review of creating four different shaders based on different transforms and improve current performance by combining transformations. Local space color World space color Scaling Over Time Effect based on distance Graphics PipelineTo create all shader effects we list at the beginning, we have to know the workflow of the general graphics pipeline and know differences between two programming shaders. Vertex Shader &amp; Fragment ShaderFrom two images below, we know that Vertex Shader process vertices and calculate transformation to projected space. The vertex’s color interpolates to fragment color. In Fragment Shader, it runs for each fragment shader and uses Vertex Shader’s output as the input to do the calculation. Status Flow LayoutThis is a simple graphics pipeline layout in OpenGL/Direct3D. Transformation Flow Shader ImplementationLocal Space ColorThe object’s color is calculated based on vertices’ position in model space. In this case, when the object moves, the modified color binds with the object, which is not changed by the world position. In order to implement this effect, fragment shader needs to use the object’s local vertex position, which is one of the parameters from vertex shaders. In Fragment Shader 1234567void main( in const float3 i_vertPosition : POSITION, //....)//.... float value = floor(frac(i_vertPosition.x) + 0.5); rVal = sin(value); World Space ColorThe difference between world space color and local space color is which type of position it uses to calculate. To use position in world space, we can directly use a converted position from the vertex shader. It is also the required data we need to output to fragment shader from the vertex shader. In Fragment Shader 123456void main( in const float4 i_position : SV_POSITION,//....)//....float gVal= floor(frac(i_position.y) + 0.5); Scaling Over TimeTo calculate scaling, we can use a scaling matrix. A scaling matrix is like below. In Vertex Shader123456 float4x4 scale = {s, 0.0f, 0.0f, 0.0f,0.0f, s, 0.0f, 0.0f,0.0f, 0.0f, s, 0.0f,0.0f, 0.0f, 0.0f, 1.0f }; We need to calculate the vertex position based on time in the vertex shader and pass it to fragment shader. In fragment Shader12vertexPosition_world = mul( vertexPosition_local,scale) ;vertexPosition_world = mul(g_transform_localToWorld, vertexPosition_world); Color Transition Over DistanceWe need to use camera transformation to get the camera world position and calculate the distance between objects. Therefore we add Math::sVector g_cameraPosition_world;in sPerFrameData and declare the buffer in the shader. Then we get the offset value do some calculation and use Lerp function to change the color. In Fragment Shader 12345float offset = g_cameraPosition_world.z-i_position.z;float s = offset/ 10;//....calculateColor.rgb = lerp(closeColor.rgb, calculateColor.rgb, s); To shrink the object over distance, we do a similar job in vertex shader using the offset as a scale factor. Combining TransformsThere are three transformations in the project: LocalToWorld, WorldToCamera, CameraToProjected. All these transformations are calculated in the vertex shader. However, we can combine these transformations into one MVP transformation: ModelViewProjectedin C++. We are passing these predefined transformations to GPU. It trades memory for realtime calculation per vertex and per fragment. Performance ComparisonThere are two instructions of Standard Vertex Shader. before using MVP: 12345678910111213141516171819202122232425vs_4_0dcl_constantbuffer CB0[8], immediateIndexeddcl_constantbuffer CB2[4], immediateIndexeddcl_input v0.xyzdcl_input v1.xyzwdcl_output_siv o0.xyzw, positiondcl_output o1.xyzwdcl_output o2.xyzdcl_temps 2mul r0.xyzw, v0.yyyy, cb2[1].xyzwmad r0.xyzw, cb2[0].xyzw, v0.xxxx, r0.xyzwmad r0.xyzw, cb2[2].xyzw, v0.zzzz, r0.xyzwadd r0.xyzw, r0.xyzw, cb2[3].xyzwmul r1.xyzw, r0.yyyy, cb0[1].xyzwmad r1.xyzw, cb0[0].xyzw, r0.xxxx, r1.xyzwmad r1.xyzw, cb0[2].xyzw, r0.zzzz, r1.xyzwmad r0.xyzw, cb0[3].xyzw, r0.wwww, r1.xyzwmul r1.xyzw, r0.yyyy, cb0[5].xyzwmad r1.xyzw, cb0[4].xyzw, r0.xxxx, r1.xyzwmad r1.xyzw, cb0[6].xyzw, r0.zzzz, r1.xyzwmad o0.xyzw, cb0[7].xyzw, r0.wwww, r1.xyzwmov o1.xyzw, v1.xyzwmov o2.xyz, v0.xyzxret // Approximately 15 instruction slots used After using MVP: 123456789101112131415dcl_constantbuffer CB2[8], immediateIndexeddcl_input v0.xyzdcl_input v1.xyzwdcl_output_siv o0.xyzw, positiondcl_output o1.xyzwdcl_output o2.xyzdcl_temps 1mul r0.xyzw, v0.yyyy, cb2[5].xyzwmad r0.xyzw, cb2[4].xyzw, v0.xxxx, r0.xyzwmad r0.xyzw, cb2[6].xyzw, v0.zzzz, r0.xyzwadd o0.xyzw, r0.xyzw, cb2[7].xyzwmov o1.xyzw, v1.xyzwmov o2.xyz, v0.xyzxret // Approximately 7 instruction slots used Order ChoiceTo get the MVP transformation, we multiply all the transformations together. In this case, we have two orders as following sharing the same result. (camera-to-projected world-to-camera) local-to-world camera-to-projected (world-to-camera local-to-world) In the project, we choose 1st way because in this case, the ViewToProjected transformation only needs to be calculated once. Then in perDrawcall, we get the MVP by multiplying the ModelMatrix. It will be N+1 multiply. However, if we apply for the 2nd order, it 2N multiply. PersonalizeControlsHold [SPACE] key to slow down the color animation. Hold [Shift] key to hide the square in the center. Hold [Ctrl] key to change four triangles color. Press [↑, ↓, ←, →] keys to move around the camera. Press [Q],[E],[Z],[C] keys to rotate camera left, right, up and down. Press [A],[S],[D],[W] keys to move around default gameobject. Press [1, 2] to select local or world effect object. Download Click Download the game. Version: x64 - DirectX.","link":"/EAE 6900 Realtime Rendering  02/"},{"title":"EAE 6900 Realtime Rendering - Materials","text":"SummaryThis writeup is a review of implementing material feature into the project. So far in the project, it uses mesh &amp; effect files to define a gameobject’s look. The effect files defines which two shader files we used in vertex and fragment. However, In real game engine, the engine have a file called material used to define how a mesh looks. A material contains what shaders we use and properties (parameters) such as tint color, diffuse texture, normal texture. Usually a material property layout depends on what shader it combines. For example, if the material combine with a shader that uses a texture, tint color, emerssive color, then the material should have these variable slots availiable for artists. In our project, we simplify the layout assuming that all materials share the same layout. The steps are listed below. Add material builder to create supported data file Add material class for engine Add material buffer passing to GPU Update shader layout to use material parameters Update render command Material BuilderJust as all the file builder we created before, the MaterialBuilder loads a human readable file and converted to a binary file. The binary file is loaded by the engine. LayoutThe material file contains a the effect path and several other parameters. As what we said above, a effect path is required for each material. Right now we have not implemented the tetxure module, so the material file only has a color property which is passed to GPU. The layout is defined as following: GreenSolid Material 123456return{ tintColor={0,1,0,1}, effectPath={\"Effects/Solid.effect\"},} Assets To BuildUpdate the AssetBuildFunctions, the material builder will automatically build effects based on materials. In AssetToBuild list, we don’t need effects list anymore. 12345678910effects ={},materials ={ { path = \"Materials/redStandard.material\"}, { path = \"Materials/yellowStandard.material\"}, { path = \"Materials/greenStandard.material\"}, { path = \"Materials/whiteLocal.material\"},}, Optional PropertyUsually, all the variable would have a default value for its own. Therefore, we use white color as defaut value for color parameter. Since when use mutiply calculation, white color won’t affect current color in the shader. In this case, a material doesn’t have the tintColor property, the MaterialBuilder creates a white color for the variable and convert it into a binary file. WhiteLocal Material 1234return{ effectPath={&quot;Effects/Local.effect&quot;},} BinaryThe binary file look like below. You can see RGBA color values come first. Then continues with a effect path. RendercMaterialAfter creating the data file, we need to create a cMaterial class to use the material data. It is similar to the way we use cEffect that after initializing, the class holds a file handle. The cGameobject has a meshHandle &amp; a materialHandle; The cMaterial has a EffectHandle; The cEffect has two ShaderHandle. The initialization is as following: 12345if (!(result = Graphics::cMaterial::MaterialFactory(&quot;data/Materials/greenStandard.material&quot;, s_greenStandard_Mat))){ EAE6320_ASSERT(false); goto OnExit;} SubmissionRight now, we can use material replacing effects. In our cMyGame, the gameobject needs a meshHandle &amp; a materialHandle to define its look. 1teapot.LoadRenderInfo(s_meshHandle, s_MaterialHandle); Material BufferIn order to use material in shader, we need to pass parameters into GPU in a buffer. So we create a sPerMaterial struct as sPerFrame data and bind the properties with shaders. 1234struct sPerMaterial{ Color g_tintColor={1,0,0,1};}; Render CommandWe still need to keep EffectHandleIndex to group up all the mesh instances, but we don’t want to pass same material several times causing wastes. So we add MaterialHandleIndex as secondary order. Layout 57 - 64 -&gt; Effect Handle Index 49 - 56 -&gt; Material Handle Index 39 - 48 -&gt; Depth Value 9 - 16 -&gt; Mesh Handle Index 1 - 8 -&gt; Array Index (Use this index to get the mesh data such as transforms) ScreenShotRenderThe order of things being rendered that demonstrates that draw calls are being sorted by materials. GPU TimelineThis is the event list when drawing red solid material objects and yellow solid material. The calls in green are for specific draw calls the calls in red show when new material data is being set PersonalizeControlsHold [SPACE] key to slow down the color animation. Hold [Shift] key to hide the square in the center. Hold [Ctrl] key to change four triangles color. Press [↑, ↓, ←, →] keys to move around the camera. Press [Q],[E],[Z],[C] keys to rotate camera left, right, up and down. Press [A],[S],[D],[W] keys to move around default gameobject. Press [1, 2] to select local or world effect object. Download Click Download the game. Version: x64 - DirectX.","link":"/EAE 6900 Realtime Rendering  04/"},{"title":"EAE 6320 Engineering II -  08  Binary Mesh Loader","text":"In this assignment, the goal is to change human readale assets into binary assets and replace implementation in cMesh. Points Design binary file format. Change the implementation of cMeshBuilder. Click Download the game. ProcessMeshBuilderIn previous assignments, the cMeshBuilder only copy mesh source files into data folder. This time, cMeshBuilder would load mesh file from Maya outputs and convert them into binary files. In order to keep track of different parts of vertex information. We have to devide mesh into four parts as vertex data, vertex count, index data, index count. cMeshIn cMesh, I update LoadAsset method, which would be called by cMananger. Below is the implementation of extracting data from binary files. Load Binary Asset1234567891011121314151617181920 //.... // Load Binary AssetPlatform::sDataFromFile pData;Platform::LoadBinaryFile(i_path, pData);uintptr_t start = reinterpret_cast&lt;uintptr_t&gt;(pData.data);uintptr_t current = start;uint16_t vCnt = *reinterpret_cast&lt;uint16_t*&gt;(current);current += sizeof(vCnt);auto vData = reinterpret_cast&lt;VertexFormats::sMesh*&gt;(current);current += sizeof(VertexFormats::sMesh)*vCnt;uint16_t iCnt = *reinterpret_cast&lt;uint16_t*&gt;(current);current += sizeof(iCnt);auto iData = reinterpret_cast&lt;uint16_t*&gt;(current);current+= sizeof(uint16_t)*iCnt; //....return result; AssetBuildFunctions.luaInside AssetBuildFunctions, I change file extension of binary file into [.bin]. So that it can make obvious difference from the human readable files. Binary FileFormatPlane Mesh Order VertexCount (Red Rect) VertexData (Follow Red Rect) IndexCount (Orange Rect) IndexData (Follow Orange Rect) In this way, it’s easier to recognize vertex content and easier to access data when loading in runtime. Advantages Loading data is faster in runtime. Since you only need to access address and all the data is already in binary format. Less storage space compare to text. With different char set, one number or character may take up mutiple bytes. Binary format only take fixed space for diffrent length of numbers. Friendly for serialization. Support serialization to make a class in binary content. Platform Independent I don’t think we need to make different formats for each platform. Because like most engines, they support certain kinds of assets type. Users like artists should follow certain or standard rules to create assets. Binary assets are used to improve efficiency during runtime rather than store assets to modify in the future. It’s more like a mid output from original assets, so keeping one format is better. Utah Teapotsize Lua File : 1493 KB Binary File: 334 KB These size can be even smaller if we use certain kinds of compress algorithm to reduce the lua file size. Time Human Readable File ： 0.0539135 s 12345672&gt;Building MyGame_ Assets2&gt;Iterating through every Vertex path:2&gt; Vertex Count 189572&gt;Iterating through every Index path:2&gt;Index Lua Count 63192&gt;Time :0.05391352&gt;Built C:\\Users\\u1157989\\Documents\\GitHub\\MI_CHEN\\MyGame_\\Content\\meshes/teapot.mesh Binary File 1duration=0.00021699007940861669 Capture PersonalizeControlsHold [SPACE] key to slow down the color animation. Hold [Shift] key to hide the square in the center. Hold [Ctrl] key to change four triangles color. Press [↑, ↓, ←, →] keys to move around camera. Press [Q],[E],[Z],[C] keys to rotate camera left, right, up and down. Press [A],[S],[D],[W] keys to move around default gameobject. Press [1],[2] keys to switch default gameobject’s mesh. [1] -&gt; Teapot; [2] -&gt; Circle Screen Shots Download Click Download the game. Version: x64 - DirectX.","link":"/EAE 6320 Write-up 08/"},{"title":"EAE 6900 Realtime Rendering - Transparent Material","text":"SummaryIn this post, we continue to add features to the materials. The last post, we implemented materials that contain a tint color., which is solid. In a real game, we often need to use transparent materials to make effects such as glass. To add a transparent feature, we need to use the alpha channel in color to determine the transparency of the material. After that, we need to care about the render order of transparent material. Instead of replacing the color behind the object, the transparent material’s color need to blend with other materials’ color so that the transparent material should be rendered after all solid material color, and also, rendered from far to close. Use the Alpha Value Change Render Order Render StateTo support alpha value, we need to tell d3d context to enable the AlphaTransparency. This RenderState bit is already defined in the effect assets. 12345678return{ -- flag order --1.DepthBuffering 2.AlphaTransparency 3.DrawingBothTriangleSides renderState={1,0,0}, vfShaders={&quot;shaders/vertex/standard.shader&quot;,&quot;shaders/fragment/localspace.shader&quot;},} Render OrderDependent Material &amp; Independent MaterialA dependent material is whose look would be affected by other materials. Like the material behind it. Whereas the independent material is a solid material, which would cover materials behind. Therefore the first step is to split materials into two groups. The independent materials should render as previous way first: close to far. Then dependent materials render from far to close. Render Cmd Encoding - FlagIn the project, I use render state to determine whether the material is independent or not. The render command is sorted from low to high. So we can let the independent material has 0 value in the highest bit of render command; the dependent material has 1 value in the highest bit of render command. In this way, we don’t need to add extra logic for transparency. 12auto iDependent= cEffect::s_manager.UnsafeGet(effectIdx)-&gt;s_renderState.IsAlphaTransparencyEnabled()?1:0; The layout is different in independent materials and dependent materials. The independent materials should be sorted by depth first then effect groups and material groups. Independent layout 64 -&gt; Dependent Flag 56 - 63 -&gt; Effect Handle Index 48 - 55 -&gt; Material Handle Index 38 - 47 -&gt; Depth Value 9 - 16 -&gt; Mesh Handle Index 1 - 8 -&gt; Array Index (Use this index to get the mesh data such as transforms) Independent layout 64 -&gt; Dependent Flag 54 - 63 -&gt; Depth Value 46 - 53 -&gt; Effect Handle Index 38 - 45 -&gt; Material Handle Index 9 - 16 -&gt; Mesh Handle Index 1 - 8 -&gt; Array Index (Use this index to get the mesh data such as transforms) Render Cmd Encoding - Depth ValueWe still want to keep the same order rule after adding transparency. So for the dependent material, the depth value encoded into render command is not the Z_Value. The depth value is MAX_Z_Value - normalized_Z_Value. 123zVal = round((-zVal - 0.3f) / (1000 - 0.3f) * 1024);if (iDependent) zVal = 1024 - zVal; ScreenShotRender This is the render order. You can see all the independent materials are rendered first. Same independent materials draw from near to far. Then independent materials are rendered from far to near. PersonalizeControlsHold [SPACE] key to slow down the color animation. Hold [Shift] key to hide the square in the center. Hold [Ctrl] key to change four triangles color. Press [↑, ↓, ←, →] keys to move around the camera. Press [Q],[E],[Z],[C] keys to rotate camera left, right, up and down. Press [A],[S],[D],[W] keys to move around default gameobject. Press [1, 2] to select local or world effect object. Download Click Download the game. Version: x64 - DirectX.","link":"/EAE 6900 Realtime Rendering  05/"},{"title":"EAE 6900 Realtime Rendering - Lighting","text":"SummaryIn this post, we add the lighting system into our engine. Add normal data into our mesh Calculate color in the Lambert model Add directional light object Add ambient color Update shaders NormalsTriangle NormalsThe normal of a plane is a vector of length one that is perpendicular to this plane. Vertex NormalsBy extension, we call the normal of a vertex the combination of the normals of the surroundings triangles. This is handy because, in vertex shaders, we deal with vertices, not triangles, so it’s better to have information on the vertex. ImplementJust as how we added the UV data. We need to add corresponding structure into our sVertex and pass data to GPU through D3D11_INPUT_ELEMENT_DESC in C++. After updating LayoutInput file, you could see the normal data in the GPU Debugger as following: Light &amp; Ambient ColorDiffuse Light According to Lambert's cosine law, when we compute the color of a pixel, the angle between the incoming light and the surface’s normal matters. Generally speaking, if the light is perpendicular to the surface, it is concentrated on a small surface. If it arrives at a grazing angle, the same quantity of light spreads on a greater surface, which means the point of the surface looks darker. Normals (Blue) Light (Orange) Lambertian model diffuse = I*cosθ; cosθ = L*N; Shader123float cosTheta = dot( normal,lightDirction );color = LightColor * cosTheta; light direction is goes from the object surface to the light source. Both are unit vector In this case, if the surface is in the opposite of the light, the cosTheta would become a negative value. While the color value should clamp into [0,1]. Therefore, we clamp cosTheta into [0,1]. 1float cosTheta =clamp(dot( normal,lightDirction )); ImplementationThere are three spaces we can do lighting calculation: local space, world space, view space. In my implementation, I choose world space for the diffuse light model. Because it doesn’t depend on the view direction and world space is easier to understand. When doing a specular light model, I might need to do the calculation in view space. I guess. Guessing. In C++, we pass the light rotation and color to GPU. Since the light data in a frame is a constant data, I put light rotation and light color in sPerFrameData Then in the vertex shader, we transform normals into world space. Since we won’t have a non-uniform scale or shear in the project, I used a float3x3 rotation matrix to transform the local normals into world space. 1const float3 normal_world = mul( rotation_localToWorld, i_normal_local ); Finally, we calculate the light color in the fragment shader. MoreAfter testing, I create diffuse lighting function in shader.inc for easy use. 12#define CalculateLighting_multiplicative( i_normal_world ) // Implementation Use 12345float4 color_multiplicativeLighting = saturate((color_directional + g_ambientColor).rgba);o_color = textureColor*g_tintColor *i_color*color_multiplicativeLighting; Screen Shot PersonalizeControlsHold [SPACE] key to slow down the color animation. Hold [Shift] key to hide the square in the center. Hold [Ctrl] key to change four triangles color. Press [↑, ↓, ←, →] keys to move around the camera. Press [Q],[E],[Z],[C] keys to rotate camera left, right, up and down. Press [A],[S],[D],[W] keys to move around default gameobject. Press [I],[K],[J],[L] keys to rotate Light up, down, left and right. Download Click Download the game. Version: x64 - DirectX.","link":"/EAE 6900 Realtime Rendering  08/"},{"title":"EAE 6900 Realtime Rendering - Texture","text":"SummaryIn this post, we add diffuse textures into our engine so that the meshes can use texture, which can give more render details. Add textures assets Update material struct Load textures in engine Load mesh texture coordinate (UV) Pass textures to GPU Pass UV to GPU Updates Shader Texture BuilderSetupBecause we have made many assets builders for this project, John-Paul gives us the texture builder project. For this part, all we need to do is integrating texture builder into current engine systems. Since the builder supports OpenGL &amp; D3D, we need to deal with platform specific files as well as an external library. Once we set up the texture builder, we also need to add cTexture &amp; cSampler classes to our engine system. These two files are similar to cMesh,cEffects,cMaterial we created before, which are used to load files and keep as file handles in the engine. Material DependencyFor diffuse textures, normal maps and other textures that belongs to materials, we implement the building flow smartly. Rather than specifically list all the textures in the Lua file, the building system will find the textures references in all materials and build the texture assets. Layout 1234567return{ tintColor={1,1,1,1}, effectPath={&quot;Effects/Solid.effect&quot;}, albedo={&quot;Textures/Yo.png&quot;},} Later if we have many textures like normal map and specular texture, I would update the layout adding textures type specifically. Load &amp; PassUVLoadIn shader, we need to UV to get a texel from an image. Usually, the UV data come along with vertice data from DDS tools like Maya. Currently, the sMesh only has Position &amp; Color data, so we need to add UV data and export the information from MayaExportBuilder. Keep in mind that the UV order is different in OpenGL &amp; D3D. Pass Then you need to updates d3dLayoutDescription to pass new vertex buffer to GPU registers. After that in GPU Debugger, you can see the TEXCOORD data information. TexturePass According to D3D documents: All buffers—constant, texture, sampler, or other—must have a register defined so the GPU can access them. Each shader stage allows up to 15 constant buffers, and each buffer can hold up to 4,096 constant variables. The register-usage declaration syntax is as follows: b#: A register for a constant buffer (cbuffer). t#: A register for a texture buffer (tbuffer). s#: A register for a sampler. (A sampler defines the lookup behavior for texels in the texture resource.) To use a texture in D3D, we need to register Texture and Sampler buffers to GPU. First, we need to update Shader.inc. Layout to be platform-independent. Then when rendering, we need to bind the buffers. For the sampler buffer we could assume we always have one sampler in our game so that it can be bind at the initialization phase. For the Texture, to improve the performance, we should only bind the texture when data changes. ShaderAfter we update d3dLayoutDescription, we need to update the VertexLayout to match with the vertex buffer data. Then in Vertex Shader, you can use semanticsTEXCOORD to get the buffer from the register, use the data and pass it to Fragment Shader Then in Fragment Shader, you can get the image texel and mix with the vertex color by the following shader. 1float4 justColor = SampleTexture2d(g_diffuse_texture, g_diffuse_samplerState, i_uv.xy); ScreenShotRender DebuggerFrom the timeline, you can see the textures would only bind when new textures need to be rendered. Red calls are binding new textures. Green call is drawing mesh instances. PersonalizeControlsHold [SPACE] key to slow down the color animation. Hold [Shift] key to hide the square in the center. Hold [Ctrl] key to change four triangles color. Press [↑, ↓, ←, →] keys to move around the camera. Press [Q],[E],[Z],[C] keys to rotate camera left, right, up and down. Press [A],[S],[D],[W] keys to move around default gameobject. Press [1, 2] to select local or world effect object. Download Click Download the game. Version: x64 - DirectX.","link":"/EAE 6900 Realtime Rendering  06/"},{"title":"EAE 6900 Realtime Rendering - Sampler, Mipmap, UV Animation","text":"SummaryIn this post, we implemented a UV animation shader and made further research on mipmap, sampler. SamplerFilteringAccording to Direct3D documents: If the primitive has a texture, Direct3D must use that texture to produce a color for each pixel in the primitive’s 2D rendered image. For every pixel in the primitive’s on-screen image, it must obtain a color value from the texture. This process is called texture filtering. Screen ShotsIn our project: You can see the difference between two filtering modes. The one uses bilinear filtering have smooth blended color than the point sampling one. Sampling Type InstanceConsider a texture that is mapped to geometry with more fragments than texels. If you simply took the closest texel for the texture coordinate in each fragment, then you would get a result like the first image: MipMapInstanceConsider having a high-resolution texture on a mesh plane. When this texture is viewed from a close distance, everything is visually in place, however, when viewed from a distance, the texture becomes distorted and out of place. The distortion is also called Moire Pattern. Solution Mip-maps are primarily used to eliminate aliasing artifacts in textures under minification by pre-calculating smaller versions of the texture. Although these additional textures consume GPU memory—about 33 percent more than the original texture—they’re also more efficient because more of their surface area fits in the GPU texture cache and its contents achieve higher utilization. ScreenShotsUse Mipmap: No mater how far or close the texture is, the texture always remain good quality. The pixel in the image remain clear to render. Disable Mipmap: When the texture goes far away, it looks distorted. It is because the GPU could not determine which texel to use to make a pixel color. Mip LevelIn GPU Debugger, you can check different mip levels as follows: Alpha TransparencyWe can use DirectX alpha transparency to make alpha texels as alpha color. We also can use a shader to get the alpha value from a texture and cutoff the texel by threshold defined in the shader. These two ways can have different results. If use a shader to a cutoff pixel, a pixel only has two status - On or Off. Therefore the edges of the opaque area become sharp. See effects below. Standard alpha transparency Cutoff Shader You may notice Harvey’s hair looks more natural in the first picture. Animated River ShaderUV &amp; TillingWe know that the vertex uses UV data to get a texel from an image. Therefore to get an animated texture in runtime, we need to change UV over time. The common way is changing UV value based on time, which means the UV could go beyond [0,1]. In this case, we need to set our sampler mode to tile that the texture will repeat outside of [0,1]. AssetsFirst, make a rectangle mesh in Maya and change its v range in [0,0.5]. The mesh would only use the bottom part of the texture. The texture in the plane is a square texture. ShaderWhether in Vertex Shader or Fragment Shader, calculate offset value over time and updates a new UV called ScrollUV. Then use ScrollUV get texel from an image. 1float xScrollValue = speed * g_elapsedSecondCount_simulationTime; Screen Shots Animated Frames ShaderWe can use a frame sheet to make animated picture. The most common case in the game is creating frames in a particle. Here we just use nine frames from an anime. AssetsFirst, make an atlas that contains 9 frames as below. The mesh only use one frame at a time, which means it takes 1/3 range in X and 1/3 range in Y. ShaderWhether in Vertex Shader or Fragment Shader, calculate offset value over time and updates a new UV called ScrollUV. Then calculate out current frame index and update the ScrollUV to that frame. 123float index = floor(10*g_elapsedSecondCount_simulationTime);float xScrollValue =index%3*0.33333;float yScrollValue = floor((index/3.0))*0.33333; Screen Shots PersonalizeControlsHold [SPACE] key to slow down the color animation. Hold [Shift] key to hide the square in the center. Hold [Ctrl] key to change four triangles color. Press [↑, ↓, ←, →] keys to move around the camera. Press [Q],[E],[Z],[C] keys to rotate camera left, right, up and down. Press [A],[S],[D],[W] keys to move around default gameobject. Press [1, 2] to select local or world effect object. Download Click Download the game. Version: x64 - DirectX.","link":"/EAE 6900 Realtime Rendering  07/"},{"title":"Unity Hotfix Solution (xLua, AssetBundle) —— Overview","text":"IntroductionThis is a research topic I delivered in EAE @ UOU recently. It includes a hotfix solution in commercial game based on Unity. The serials and example demo covers - in Unity : Assets Updating Solution Based on Versions (AssetBundle, Unzip) Using Lua hotfix game logic in runtime (xLua) The example bases on Complete Project from Unity Technology - Survive Shooter. It stimulate the task to add hotfix feature in a published game. Since this is a research topic, for each section, I would write related introduction post. CaseAfter publishing games, you may want to update game content. Like in a MOBA game: It always needs to add more charaters and in most cases, the new character won’t change game logic. To balance the battle, developers need to change the attack range which also needs to be changed in skill indicator in client. Change map for different holidays or events. [Bad Choice] Rebuild. Why? AppStore needs to check new builds and could be rejected due to new changes. Users need to re-download the game again for tiny changes. Not flexible. [Ideally] What we want. Only download &amp; updates game content that changes. Rewrite game logic. Straightforward , change the implementation in the game. Then you need a [Hotfix] solution. SolutionThere are two parts in game content. One is codes, which will be compiled into dll in Unity. The rest like models, materials, audios can be treated as assets. AssetsWe can use Unity build-in system to update the Assets content. But for codes, Unity doesn’t have solution for that. The asset managing system in Unity used for updating is AssetBundle. You can check [TO-BE-ADD] for details and follow instructions to learn how to use. CodesReflectionGenerally, C# has reflect feature which can be used to change logic in DLL. However, why not using reflection ? AppStore doesn’t allow you use the feature because they think it is unsafe. The game industry has used scripts language for fixing bugs. For this topic, I would use xLua in Unity and stimulate updating tasks in real world. Check [TO-BE-ADD] for details and follow instructions to learn how to use. Demo SetupFor this topic, the project use Unity 2017. All different versions of Unity 2017 works. In AssetStore, download [Unity-Chan] and [Survive Shooter]. That’s all. See you in next post.","link":"/HT_Overview/"},{"title":"Unity Hotfix Solution (xLua, AssetBundle) - AssetBundle, Updating Strategy","text":"SummaryIn this post, we will talk about the use of AssetBundle, simple game updating (hotfix) model, which used as reference for further learning. It covers: Resources Type ( General Resources, AssetBundle, StreamingAssets, PersistentDataPath General Updating Model Build and Load Optimization of Dependency and Manifest Walk-through Demo OverviewAn AssetBundle is an archive file containing platform specific Assets (Models, Textures, Prefabs, Audio clips, and even entire Scenes) that can be loaded at runtime. The AssetBundle system provides a method for storing one or more files in an archival format that Unity can index and serialize. AssetBundles are Unity’s primary tool for the delivery and updating of non-code content after installation. This permits developers to submit a smaller app package, minimize runtime memory pressure, and selectively load content optimized for the end-user’s device. Therefore we can use it make DLC updating levels. Like in last post, we may want to update game content during social holidays without letting users download whole game again. The other factor is that app store usually has a maximum size limits for different games and we can reduce the pacakge size by AssetBundle. The game I’ve published during working in Beijing, requires the initial package is less than 200 MB in one Android store. Because Google Play Store is banned in China, there are lots of third-party stores having different requirements. Resources TypesBefore moving on, It’s better to analyze different ways to handle assets in Unity. The most common ways are Resources, StreamingAssets, AssetBundle, PersistentData. ResourcesThis is the easiest way to load asset in Unity. You should know that : Read Only. Built Into .assets File In Package. Load in Main Thread. According to official best practices for Resources System it says: Don’t use it. This strong recommendation is made for several reasons: Use of the Resources folder makes fine-grained memory management more difficult Improper use of Resources folders will increase application startup time and the length of builds As the number of Resources folders increases, management of the Assets within those folders becomes very difficultThe Resources system degrades a project’s ability to deliver custom content to specific platforms and eliminates the possibility of incremental content upgrades AssetBundle Variants are Unity’s primary tool for adjusting content on a per-device basis Streaming AssetsPretty like Resources. It usually used to store binary files that is able to be shipped with game. Difference Streaming Assets would not be encrypted. Resources Assets would. (Still can be decompiled) Features Read only [Mobile Devices] PersistentData AssetsLike Streaming Assets. Difference Writable/Readable in runtime. Only in runtime. In Application Sandbox. (Android can be sdCard) No Data Limits. (AssetBundle, Binary File) Features Read only [Mobile Devices] Updating Work-flowModelBelow is the prototype of the game [] published. .png) Usually we may prefer zip content package and unzip in client. Asset BundleBuildLike the flow chart, before updating, you have to create asset package in editor. Generally in a project, developers will build editor to manage build flow. Assign [Asset Tag] in Editor. Use BuildPipeline.BuildAssetBundles(Path, BuildAssetBundleOptions, BuildTarget); build assets. Zip AssetsBundle and upload to server. You can check more details in walk-though Section. BuildAssetBundleOptions .None:Use LZMA compress, small size, slow loading. .UncompressedAssetBundle: big size, fast loading. .ChunkBasedCompression:Use LZ4 compress, small size, fast loading. BuildTarget Platform Specific. Load Load AssestBundle Use AssetBundle.LoadFromFile, UnityWebRequest,WWW.LoadFromCacheOrDownload load Load Assets 1T obj = assetbundle.LoadAsset&lt;T&gt;(assetName); Use as normal AssetBundle.LoadFromFile is most effective; In Unity 2017, WWW class is wrapper of UnityWebRequest. Resources Assets Bundle [AB Name] Asset1 [Asset Name] Asset2 [Asset Name] Manifest DependencyExample:Assume material A refers to texture B. Material A is packaged into AssetBundle 1, and texture B is packaged into AssetBundle 2. [Picture] In this use case, AssetBundle 2 must be loaded prior to loading Material A out of AssetBundle 1. This does not imply that AssetBundle 2 must be loaded before AssetBundle 1, or that Texture B must be loaded explicitly from AssetBundle 2. It is sufficient to have AssetBundle 2 loaded prior to loading Material A out of AssetBundle 1. However, Unity will not automatically load AssetBundle 2 when AssetBundle 1 is loaded. This must be done manually in script code. ManifestTo query the dependencies of a specific AssetBundle: AssetBundleManifest.GetAllDependencies, AssetBundleManifest.GetDirectDependencies For instance: 12345678910111213141516#region Manifest var request = UnityWebRequest.GetAssetBundle(&quot;AB_Path&quot;); yield return request.Send(); var ab = DownloadHandlerAssetBundle.GetContent(request); var manifest = ab.LoadAsset&lt;AssetBundleManifest&gt;(&quot;AssetBundleManifest&quot;); var resNameList = manifest.GetAllDependencies(&quot;AB_NAME&quot;); foreach (string resName in resNameList) { AssetBundle.LoadFromFile(&quot;PATH&quot;+resName); } #endregion SizeThe size superbly decreases after using dependency. Check result You can check more details in walk-though Section.","link":"/HT_AssestBundle/"},{"title":"去美国，学游戏","text":"最开始准备这次留学是很仓促的，并不像很多朋友想的那样，嗨呀，做了两年游戏开发，积累了经验，一切按照计划有条不紊，水到渠成的去镀个金。事实上，我在参与上线的第一个商业项目上线两个月后，项目盈利日子开始舒服起来，再有一周全公司飞韩国见美女小姐姐吃肉喝酒的时候，从公司撤回家，大家乱嗨的时候，我穿着条内裤在家对着托福成绩发愁，去年七月的时候连托福要考啥都不清楚。 冠哥高义，且不算我辞职，权当是长假在家，但该是逃兵还是逃兵，申请的准备实在仓促了些。若不是年前，正好新开了MMOARPG项目缺人招了回去，我这简历写起来也是尴尬无比。回公司和大佬们聊了下读研期间的学习方向，十几年的从业经验，大佬们的建议确实比自己周全很多。 Entertainment Arts &amp; Engineering @ U因为打算一直Focus在游戏数字媒体相关的领域（起码现阶段），所以申请的时候一般的CS专业都没选，这个我猜让规划老师有点头疼，但接触了游戏开发之后，越来越发现开发游戏和开发系统类型的APP从开发方法、流程、思维设计角度来讲都不一样。而对于代码层面的技术，当某种语言掌握到一定程度，对一般的软件工程设计思想有所理解后，编程语言的学习更像是一种工具技能，并非是必须从课堂教授口中获取。又或者说，专业领域的学习不是某种语言的语法规则，使用习惯等。 进入游戏公司后，愈发的觉着游戏制作是一个TEAM WORK，而且是不同的生产线的集合，从多种角色到每种角色自身专业领域的划分。这种多领域的结合其实是一个非常奇妙的过程，就像当年在美术学院死磕的日子： ORZ，什么是IK，什么是Mesh，什么是蒙皮，我一个程序怎么要知道这么多。值得一提的是当时给我解释IK的王老师用了一个简单粗暴但非常直接的办法：拿起我的左手来回推拉，然后问：动了吧？ -嗯，动了。 懂了吧？ -嗯，懂了。 Gay里Gay气。 EAE就是这么一个多种Track在一起开发项目，共享一部分课程的同时又有自己领域专有的课程。Hhhhh，当时和Mark 教授Skype面试那一波商业互吹。 选择Engineering Track，首先当然是从申请背景来说，这个Track会有些优势。其次，更加想以一个比较熟悉的角色带入到整个游戏的开发制作中，这样的话，应该会留给自己更多思索比较的空间。 记得当年在深圳广州找工作，有一次笔试、二面、技术面都过了后，和广州明朝的CTO聊了半个多小时。这次面试让我一直记着是在聊天过程中的一句话，一个至今回想起来特别傻X的回答。 作为毕业生你的知识储备广度是有了，你应该朝着某一个方向进行深度的研究学习。 -你在这个公司的职业目标是什么？ -成为一个公司离开我就转不了的人。（当时真的被李总洗了脑毒害了） 第一句话现在看上去平淡无奇，但这句话所引发的问题对当时的我来说还是没太想清楚的，不太记得当时回答他的是往哪块发展，可能是图形学这块。但CTO来了一句，程序员是需要量化的，然后，好吧，当时道行还是浅了点。 第二句话那就诛心了，说完就被CTO教导了一番，原话是：公司离开谁都能转起来，每个人都有自己合适的位置，位置有高有低罢了。 于是，我之后就换了一个更加朴素的规划目标。 所以我想，或者说是我希望，在EAE学习的这段时间里，能够侧证自己的想法，更加像是一个对游戏职业探索的过程。 寄语·戒尺如果让我来描述这一次去美学游戏的经历，那应该是 久在樊笼里，复得返自然 在公司开发游戏的这段时间对我来说是一段非常宝贵的经历，从初到公司那会发现项目组里藏着一群什么样的牛鬼蛇神，国内数一数二的端游研发团队（虽然当年我看到同学玩明教的时候大骂菜鸡画面），从西山居啊、完美啊出来的美术，从Gameloft出来的测试呀，做出App Store现象级手游的策划呀，还有隐藏的终极boss呀。 有一段时间就感觉特么听着他们吹牛逼都很牛逼，虽然后来就跟着他们一起吹牛逼了。 公司里在团队在项目中的学习不会像在学校那样，不可能让大伟哥过来教我写代码，还没潇洒到饭碗都不要了。就像听他们吹逼那样，很多时候是跟大佬们的沟通过程中进行学习。这种感觉更像是一个过程的积累，好比虽然我不是PM大人，但经历完大霹雳项目，对一个项目的管（PIN）理（MING）也有（SHEN）点（YOU）认（TI）知（HUI）。 所以就会想着进步，会想着年轻的时候是不是去试试那些不确定的东西。进修还是会进修的，只不过原本打算是明年开始准备的，让自己多积累一些，离开的稍微光彩一点。 经历完工作之后，尤其是游戏公司开发，确实觉着能有一段悠闲自在自由安排学习的时间是多么的宝贵。时间就像海绵，挤一挤总是有实践学习的，但，真TM的累。单身一人的时候顾忌没有那么多，或者现在还姑且能算年轻，不想为这浮躁的社会完全妥协。 因为，我特么觉着，开发游戏的Coder本身就是个Artist啊！等到了一定年纪再来妥协吧，好歹老了能吹嘘一把，你爷爷我当年也叫阿浪。 前段时间到深圳走访亲友，两天的时间约见了七八波人，每一次约见聊下来都能看到周围的人正朝着不一样的轨迹发展起来，看到圈子之外的事情的感觉很奇妙。我这个伪金融学学生也就只能天天鼓吹当年上邹老师经济学听他讲故事那种从另一种职业思维的角度看时间的感觉，很棒。突然发现，不定期的同朋友聊聊天，是一个十分享受的过程。 这几年机缘巧合的又认识了些很厉害的同龄人，其中有一个称我为师傅的朋友。这个在顶级学府爆肝求学，对各种事情十分有规划又抗压的妹子时不时的给我莫名的压（ZHONG）力（ER）。虽然往往仍旧我行我素，但回想自己在本科的时候虽然做不到如此一般，但这意思应该有了。 想起来，确实也要肝一波了。（写到这压力君来消息了，在越南做课题资料收集）– 00点29分 来呀，互相伤害啊。 远行如果顺利，明天的这个时候应该就在旧金山了。 也没出过国，那么，远行的话。 莫听穿林打叶声，何妨吟啸且徐行。 竹杖芒鞋轻胜马，谁怕! 一蓑烟雨任平生。 Hello America! 2017年8月4日 00点42分","link":"/EAE Learning Game/"},{"title":"Unity Hotfix Solution (xLua, AssetBundle) - xLua","text":"SummaryIn this post, we will start to add xLua into our project and show how to use inside your project and interact with gameobjects. Introduction Installation Loader Lua Table, Run Lua Function Hotfix Lower Level Changes Survival Shooter Example IntroductionxLua is a framework adding Lua scripting capability to Unity. At beginning, it is internal solution in Tencent. Now it is public on Github and maintained by Tencent. It has full English documents and tutorial in the Repo. It has been used in many commercial games, which proves its stability. Installation Unpack the zip package. Drag [xLua] folder , [Plugin] folder into your project. After compiling, you can see [Xlua] menu item at the topbar. Quick Start To Use Lua Run CSharp Code 1LuaEnv.DoString(&quot;CS.UnityEngine.Debug.Log(&apos;hello world&apos;)&quot;); DoString parameter is a string, and you can enter any allowable Lua code. A LuaEnv instance is virtual machine to run the commands. Better to be unique globally. CS means CSharp, to access any functions or content inside a class, use full namespace path and add ‘CS.’ at the beginning. LoaderBy default, you can use following Lua function run Lua scripts: 1&quot;require &apos;luaVariableExample&apos;&quot; To call the lua function, like quick start, 1LuaEnv.DoString(&quot;require &apos;luaVariableExample&apos;&quot;); This is default loader in xLua. It will automatically look for [‘xxxx’.lua.txt] file inside [Resources] folder. Then run content inside the file. For instance, in Assets/Resources/luaExample.lua.txt 1print(\"Function From luaExample.txt\"); After calling DoString function, it will print txt in the console. [It’s Lua print funtion, not Unity Debug function] Customize LoaderUse LuaEnv.AddLoader. It takes delegate in wich defines how to access lua files. For example, I want to load Lua files from SteamingAssets folder not Resources file. 1234private byte[] RealLoader(ref string filePath) { return Encoding.UTF8.GetBytes(File.ReadAllText(Application.streamingAssetsPath + &quot;/_Assets/_Lua/&quot; + filePath + &quot;.lua.txt&quot;)); } After using env.AddLoader(RealLoader); to add your loader into the virtual maching. The require 'luaExample' scripts would first look file inside [StreamingAssets/_Assets/_Lua/]. If there is no file named LuaExample.lua.txt, it will continue looking inside [Resources] folder. Get Table Values, Run FunctionsAssuming we have lua file called luaVariableExample.lua.txt inside Resources folder. 1234567891011121314151617ID=1001221001Name=&quot;Chen Mi&quot;Male= trueMeshData= { position=&quot;1,2,1&quot;, scale=&quot;1&quot;,}function Test() print(&quot;This is Test Function!&quot;)endfunction Test1(a,b) print(a+b)end In order to get these values, you can use env.Global.Get&lt;T&gt;(&quot;KeyName&quot;). It also supports struct. 1234567891011121314 var id= env.Global.Get&lt;int&gt;(\"ID\"); var name= env.Global.Get&lt;string&gt;(\"Name\"); Debug.Log(\" Global Variable ID is \"+id+\" - Name is \"+name); var md= env.Global.Get&lt;MeshData&gt;(\"MeshData\"); Debug.Log(md.position+ md.scale); //..... public class MeshData{ public string position; public int scale;} For functions, it supports using delegates. You need to declare delegates first and give it an attribute [CSharpCallLua] 12[CSharpCallLua]delegate void TestFunction(int a, int b); Then you can call the lua function like below : 12LuaFunction lFunc = env.Global.Get&lt;LuaFunction&gt;(&quot;Test1&quot;);lFunc.Call(112, 1); It would give you a result 113. HotfixProject Setup Add the HOTFIX_ENABLE macro to enable this feature (to File-&gt;Build Setting-&gt;Scripting Define Symbols in Unity). Execute the XLua/Generate Code menu. Generating Wrapper. [In Editor] Execute the “XLua/Hotfix Inject In Editor” menu when developing a hotfix in the editor. WorkflowTaskWe need to overwrite Spawn() in [“Survival Shooter”] 123456789101112131415161718192021222324namespace CompleteProject{public class EnemyManager : MonoBehaviour{ void Start () { InvokeRepeating (&quot;Spawn&quot;, spawnTime, spawnTime); } void Spawn () { if(playerHealth.currentHealth &lt;= 0f) { return; } int spawnPointIndex = Random.Range (0, spawnPoints.Length); Instantiate (enemy, spawnPoints[spawnPointIndex].position, spawnPoints[spawnPointIndex].rotation); }}} Setup Give Class an Attribute [Hotfix]. In our case 12345namespace CompleteProject{ [Hotfix] public class EnemyManager : MonoBehaviour //... Give Method an Attribute [LuaCallCSharp]. In our case 123456//.... [LuaCallCSharp] void Spawn() {//.... } Run [Project Setup] step 2,3. Write Lua scripts. Use xlua.hotfix([ClassName],[FunctionName],[NewLuaFunction]).In our case 1xlua.hotfix(CS.CompleteProject.EnemyManager,&apos;Spawn&apos;,[NewLuaFunction]) Following Lua script just replace the original implementation into [Print Log]. 12345xlua.hotfix(CS.CompleteProject.EnemyManager,'Spawn',function(self)print('LOL')end) If you need to access private variables in the class from Lua function, you need to use xlua.private_accessible([ClassName]). In our case 1xlua.private_accessible(CS.CompleteProject.EnemyManager) Below is the Lua function for Spawning the enemies. 123456789101112131415xlua.private_accessible(CS.CompleteProject.EnemyManager)xlua.hotfix(CS.CompleteProject.EnemyManager,&apos;Spawn&apos;,function(self)if self.playerHealth.currentHealth&gt;50 then self.spawnTime = 1endmytable = {self.spawnPoints}local spawnIdx= CS.UnityEngine.Random.Range (0, #mytable)spawnIdx=math.floor(spawnIdx)CS.UnityEngine.GameObject.Instantiate (self.enemy, self.spawnPoints[spawnIdx].position, self.spawnPoints[spawnIdx].rotation);end) Low LevelAccording to the author, Before hotfix 1234567public class Calc{ int Add(int a, int b) { return a + b }} After hotfix, in IL, it will add codes like this: 123456789public class Calc{ static Func&lt;object, int, int, int&gt; hotfix_Add = null; int Add(int a, int b) { if (hotfix_Add != null) return hotfix_Add(this, a, b); return a + b }} When Lua calls the hotfix, the hotfix_Add will point to a reference (function). If there is no hotfix for this function, it will add a if statement.","link":"/HT_Xlua/"},{"title":"归国前后（四）— 暑期","text":"var ap = new APlayer({ element: document.getElementById(\"aplayer-gxvhkQZR\"), narrow: false, autoplay: false, showlrc: false, music: { title: \"故梦\", author: \"双笙\", url: \"https://chenmi-ink-1252570167.cos.na-siliconvalley.myqcloud.com/Music/%E5%8F%8C%E7%AC%99%20-%20%E6%95%85%E6%A2%A6.mp3\", pic: \"https://p1.music.126.net/GZJY3Iz7TacxI3pr4jvQYQ==/18007801439911769.jpg\", lrc: \"\" } }); window.aplayers || (window.aplayers = []); window.aplayers.push(ap); 学长学姐们这会儿也都毕业，大都准备着回国的事情。 硕哥、楠哥启程，晚上提一打酒过去聊聊，忘记带护照，返回去拿，后来店员说不用看我护照。 摸摸自己的脸，岁月催人老。 聊完发现楠哥也是个有故事的人呀。都是在游戏公司做过几年开发再决定出来的，想法会有些相近的地方，他说这两年在EAE一直以为他的想法有问题，直到现在才发现一个跟他考虑差不多的人。 地道北京人的风格，说起来是中传媒第一届数媒游戏毕业生，倒是吱吱的学长长长了。 喝口酒。 硕哥依旧是走技术路线，功底在那，不用担心，一只手打五个。之前Game Jam 一起合作过，很放心。 喝口酒。 年轻的时候多看看，多闯闯，终究不会错的很离谱，出来了才是一切刚刚的开始。 临走前拿了几本书，两块White Board。 祝前程似锦。 也不知道明年毕业那会儿，会是个什么样的情况，或许也能喝上两口小酒。 VA Hospital几经波折，最后到了The GApp Lab。 分配到了一个新项目，给退伍军人医院做外科手术App。 退伍军人医院属于政府单位，项目资金也是政府出的。于是，就有了一次医院外科手术参观之旅。 第一次穿的和医生一样，旁观了一个血管桥接手术，简单说似乎就是让活跃的血管给另外一个供血，充能。Super Charge。 发现了些问题，挺有意思的体验。 回来的时候，Jesse的小马达简直哗啦啦了，在美国第一碰到开这么快。 前期把功能进度推完，差不多现在就进入划水阶段了。 每次上班泡杯咖啡，两杯茶，还能空出时间刷刷题看看视频，我们项目的进度还超前许多。 起码实习而言，美国这边的上班还是很轻松的。 这儿实习的好处就是自由，体验一波美国工作的氛围，余下更多精力来准备明年的招聘。 就是这六七八月的盐湖城，很晒。 瞅一眼太阳，要瞎。 Lagoon开工后第三周周末和几个同学一起去附近的游乐场，体验了七八个过山车。 到后来几个项目，排队的时候是真想哭。 其中一个双（三）人一个座位的过山车项目，邓爷最后那一下，撕心裂肺的疼啊。 我这把老骨头经不起这样的折腾了，大概三周之后，全身的酸痛才完全消失。 贼疼，贼开心。 书路最近看书，读到一句课本学过的话，读万卷书，行万里路。 立马就和老周聊了下，买了张圣诞节前后去巴黎的票。 或许还有机会见见马赛的网友。 说起来也是一段趣事，原本金融学老师让我劝他儿子别转专业，好好学经济学。没想到后来变成安抚了一波邹老师。 老师啊，对不住了啊。 直到现在我也没找你去吃饭，当年你说的，等我找到女朋友，再请我吃个饭，让您失望了。 一半暑期大约过了一半。 有意思的人，有意思的事永远不嫌多。 人啊，越大越是珍惜一起拥有旧时光的那些朋友。 就到这里把，花了两个小时编译完跨平台的工具链，撸游戏（渲染）引擎了。 美好世界。","link":"/Summer GApp/"},{"title":"盐湖城の所遇","text":"去年备考托福的时候认识一个申读美本的小妹妹，从费城飞盐湖城的前几天刚好联系了一下，说到当时我都是从她口中得知犹他大学，还真是无心随口一提，没想到自己最终来到了这所学校。 妙不可言后来谈到她没来盐湖城的原因之一居然是因为在这认识一大票叔叔阿姨怕管着233. 后来小妹妹联系了盐湖城教会的阿姨接机，在机场进城的路上看着四周环绕的山顶，只想着这特么是真进了山沟沟了。阿姨非常热心，问着是否需要微波炉啥的，还邀请着去华人基督教会青年社团参加活动-免费蹭吃喝，中秋节前去了一次BBQ，又是唱诗又是祷告的，挺有意思，后来因为Lab各种项目，倒也是再也没过去了。想着这前后的关联倒也是有些奇妙。 到盐湖城的第一个晚上和Rikki在学园内压瞎逛到12点多再慢悠悠的走回去，恰巧星期六，路边还有些在房子里开Party的对我们Say Hi Hi Hi…. 盐湖城的日子，开始了。 暗一开始在费城联系上了的那个老乡有房源，来之前也就直接付了定金，来了之后却发现描述和相差的很大，可以称得上是欺诈了，一方面房子把客厅隔成了两个房间，还有一个小房间更像是储物间，房间内连壁灯也没有；另一方面从美国房东那得知，从他手上租出的价格比从这两位中国二房东所说的价格要低几百刀。 现在想起来还觉着十分讽刺，至今为止在美国唯一一次被坑的经历居然是两个国内博士搞得。经过一阵撕逼这事还算是解决了，不过这还是让我头一个月住的不舒服，谎言，占小便宜，也算是丰富人生了。 另一个略微坑爹的事情是刚到盐湖城那会儿，去了一家Burger店，店里的老板是个台湾人，据说这家店在学校附近开了四十年，还能看到墙上挂着的当年盐湖城冬奥会留下的照片。老板是个小大叔，跟我们聊的挺开心也很热情，留了微信。没过两天大叔微信就找上我，私下里约着去店里坐坐。吃饭的时候他提出让我入股这家店，让我投二三千刀进去，每个月再从他那拿多少分红，保底至少每月多少。 结合他前后说话前后的矛盾，再加上之后一次带我去Costco路上表现出来的一些小毛病，我感觉这事不太靠谱，后来就再也没有回复过他的消息，也没再去过那家汉堡店。开学之后没过多久，在华人群里就曝光那个小大叔老板因赌博欠债诈骗了一些学生，逃了。似乎有几个本科生直接丢了几千刀。之后那家店上就挂了For leasing的字样。 想想刚开学的那段时间，真特么有意思，这或许是远行在异乡这样一个特殊的状况下会有的经历。 居无定所那大半个月幸好碰上了几位大哥，收留了一波，生活嘛，终究还是会有向阳的一面。 715 哥，哥，哥美国房东在我交了第一个月房租后让我继续住一个月，但当时房子里的环境属于还没完全装修完且也没网没空调，各种糙，难以忍受这样的居住环境。新住所公寓的房间还需要几日才能空出来，这时幸好有一位EAE一个同学收留我去他们的house阁楼上住一段时间，并认识了三个CS大哥，其中一位是摩门教大哥，另一位阿尔伯特王子。 虽然在那住的短暂，但跟几位大哥相处很愉快，记得有一个晚上和PHD大哥正面刚了一波GIT管理，贼特么嗨的一批，听闻房东也是个有意思的人，似乎经常处于失联的状态，也不着急交水电啥的。 搬出去的那天到 Smith’s 买了些肉菜啥的和大哥们吃了一顿，人间自有真情在。 阿里嘎多。 RA Job一天早上院里发邮件，说是一名教授找一个Unity程序员做虚拟世界辅助他们做研究，瞄到教授名字一看，嘿居然是中国人，立马投了个简历。中午参加完Activision的讲座约了个面试谈妥了。后来纠结于是否能拿到学费减免，因为这个项目比较短又是中期才开始的，已经过了学校的减免申请时间。但EAE和MEC都帮忙试着提交了一次延迟的申请，无论结果如何，非常感谢他们在这个事情上花费的精力。 拿到RA后就申请了SSN，没来之前还真没想到可以这么早拿到SSN，这一波算是蛮幸运的，当然如果能减免一半的学费那就更美滋滋了。RA的话对我来说倒也不费事，老板只看产出结果，并不是一定要每天去他那工作，感恩节前最终版交付完毕就好。嘛，好的开始。 LAB &amp; 枪击EAE相关的东西应该会开单独的分类写，第一次在LAB过夜是第一个Rapid Prototype 项目。第一次还真是精力满满，两三周做了三四个不同的游戏，这下是真的体会到改需求设计真的是要了老命，核皇大人是有多么的靠谱，感谢大佬不杀之恩。 后来两三次Rapid Prototype都在Lab里过夜，每到Final Pitch的前一夜都是程序员忙碌的时候，2-3点还有十几二十人待在工作室里出版本。做第三个项目的某个晚上，就在学校周边发生了枪击事件，第一感觉是，卧槽，真的枪击了，没白来呀。看到美国同学似乎并没有太多担心，一个SFO过来的同学很是嚣张的说，没啥，不就是枪声吗，我在加州那每天都能听到。 可以，你很强。 未来计划慢慢调整过来节奏，自己的网站也要继续折腾起来了。希望能在明年三月份GDC参展的时候有点内容。 开学的时候就想着吧之前的工作项目总结出来的经验写一些技术博客，但无奈Game Design课程的阅读量简直无耻，每星期写完Reading Reflection就已经疲软。这学期快结束，EAE的情况大致摸了下，改划水的东西也下定决心划水，应该会有更多的时间来折腾自己的东西，真正的按照想法来规划剩下的这一年半生活。 后续中文博客目录依旧是记录些在美国的事情，也不知道能在这待多久，多少留点可以吹逼怀念的东西。接着会有游戏开发技术相关的博客内容，目前还不确定这部分内容是不是中英文混合，主要考虑面向的人，另外应该会单独开一个EAE的记录贴。 C’est la vie.","link":"/Things That See/"},{"title":"归国前后（三）— 从北到南","text":"var ap = new APlayer({ element: document.getElementById(\"aplayer-tmoKzUvx\"), narrow: false, autoplay: false, showlrc: false, music: { title: \"I'm yours\", author: \"Jason Mraz\", url: \"https://chenmi-ink-1252570167.cos.na-siliconvalley.myqcloud.com/Music/Edeema%20-%20I%27m%20Yours.mp3\", pic: \"https://i3.sndcdn.com/artworks-000125122878-zogvqz-t500x500.jpg\", lrc: \"\" } }); window.aplayers || (window.aplayers = []); window.aplayers.push(ap); 回来前规划了下路径，为了省点路费也是拼尽脑力，往返大约500刀，包括国内一趟从深圳飞北京的。 计划是落地北京，之后到宜春、南昌、再南下广州、深圳。 出发的头天晚上，在一楼洗衣服时候，一小姐姐排在我前面付钱，问了下我的号码，直接一起付了。 真开心。室友要我晚上留门。 机场 &amp; 礼物何老板要我回来的时候帮她带几瓶雅诗兰黛的化妆品。 我一钢铁直男哪会知道，化妆品同一系列的瓶子颜色大小都差不多，被吐槽了一顿。 后来发了截图给我，我回了个OJBK，到了免税店的时候，小姐姐问我是不是日霜。 并不是十分肯定的说，应该是的。所幸没带错，不然就要挨打了。 临行前到了Campus Store买了一堆钥匙串、帽子、酒壶纪念品。花了RMB1500，肆爷吐槽说淘宝上也就150。 所以在这边每次买到了Made In China 都感觉亏了几百个亿。 到了国内给礼物的时候，小舅舅把我拉到一边，半吐槽说，送男的带这些帽子钥匙串可以，给女生送这些就不合适了，应该要点化妆品什么的。 大概也是我这钢铁直男，真的没有什么应对妹子经验吧。 礼物一事被各个朋友吐槽着。 要是姜姜没把NYX的遮瑕霜拍跟颜料板那么大，要是我知道就只有巴掌那么大小，买它十个八个又有何惧。 给爸妈带钥匙扣和网球帽，一个MOM，一个DAD。 他们很开心。 北京盐湖城飞西雅图值机时问我，为什么只带个小箱子，不装一两箱Candy回去，反正也是托运。 心想，到北京岂不是累死，再看同行的小哥哥小姐姐，好吧，是我懒。 西雅图飞北京的航班是海航的，坐完之后决定以后国际航班能坐国内的就坐国内的。 小姐姐又漂亮，东西又好吃。 从地铁站出来后，原本想在东三环附近直接打车去公司，没想到老北京师傅就是实在，说这个点这块太挤了，让我接着去坐地铁。 朋友圈里都是吐槽，为啥上海（北京）那么大，平坦的路走多了，上个楼就喘了，一号线地铁怎么会没电梯。 久违了密密麻麻的人头，刚开始还有点害怕。 抬头望望天，感觉蓝了不少。 少年时代四点下的飞机，大约八点到了公司，大伟哥、老板&amp;娘都等着没吃饭。 辛苦了各位，我的锅。 发现老板穿的皮夹克后面是Salt Lake City，就打趣说，怎么穿了我们那的衣服。 老板倒是回了句，你还没拿到美国身份呢。 到了海底捞吃了下网红菜，聊来聊去，一些选择取舍方面的想法。 回来的时候舒哥说了句，别让出国这段经历反而阻碍了你的选择，很有道理。 接着被嘲讽了一波，还年轻，别以为都知道。 嘛，可是每个年龄都有每个年龄的想法。 大佬们聊了聊过去在大公司的经历，舒哥说之前几次去GDC的情况，问我拿了多少东西。 嗯，有点不要脸的多了，暑假的时候嘲笑自己，就是个移动广告牌。 所处的环境容易对人造成影响，在这些变化之中不断地调整，最后回归初心可能也是一个需要经历的过程。 能在从业最开始遇到大家，是我之所幸。虽不曾当面说，但确是发自内心的庆幸与感激。 唯有守心，方是一人。 解了乌克兰之谜，遗憾的是没见到我那位肠胃不好的越南战友，枪林弹雨中过了命的交情啊。 三度朝圣在附近粥立方吃了个早饭，想了想大三暑假第一次上京，拿着腾讯地图，拖了个箱子，一人就过来了。 公司附近也有个粥立方，不过那会儿吃饭的心情和现在不一样。 第二天又去了下清华，在附近和吱吱吃了个饭。 感觉又高了不少，仰头看了，不过，2333，脸圆了一圈。 另外一位总有种这辈子再也见不到的感觉。 同样见不到的还有诗诗，次次错过。 -绝症了一定要说一句，打飞的也过来看你一眼。 -就一眼？ 不捐点钱啥的？ -都绝症了还浪费这钱干啥。请你吃顿好的得了，冷面凉皮随便挑。 似乎能成为学霸，都会很忙碌的样子。 每次来清华感觉跟朝圣一样，少壮不努力老大徒伤悲，直到现在也没去北大看看。 北京这趟也就结束了。 江西回来之后忍不住，吃了炒粉和麻辣，直到回到SLC还在拉肚子，可就是要吃，东西嘛，都是吃一口少一口，及时行乐。 老赵也从日本回来了，何老板他们一起约了个饭。结账时候的玄机，现在确实有点跟不上节奏了。 过了几天老赵去广州面试，再没过几天，吐槽太热就回来了。 也是，浪啊。 南昌和班花约了下，聊了会，听她吐槽了波回国后在软件公司工作的情况，还是决定进高校当老师。 有一天她说要继续练英语，下了个APP，参加了个活动，坚持半年每天30分钟就可以全退学费。 想了想自己在这边坑坑洼洼的交流，也就一起报了个班。 然而，她已经断了一天，我还在坚持。 开心。 前几天出结果了，恭喜。 回学校的时候去了趟美院，感觉除了每届毕业生不一样，其它的一切如故，实验室也更有起色了。 后来想了想，或许高校最大的症结就是在于无法保证稳定的进度，以及项目本身执行人员的基础技能。 不能依赖于教授事必躬亲。而学生毕竟处于学习阶段，对项目内容以及时间安排缺少经验和认知。 还有些情况下，并不遵守游戏规则，也是无可奈何，只能敬而远之。 中午一起吃完饭后，去了院长大人办公室大约聊了一个点，说了些可能是作为毕业生对本科阶段的反思（和一些愿望?）。 期间院长一句话也是一针见血，像清华北大的学生，整体素质更好，导师分下的课题之后，看着他们答辩就能够更加了解新的技术。 而这边很多时候还需要老师自己研究带一带，两者差距可见一斑。 当时想了想吱吱的情况，能拿到微信的接口做数据分析，大抵也就是这样了。 究其根底，人自欺则天欺之，人自强则天予之，走好脚下的路。 回来的时候，座位旁边的是位做区块链的大佬，听他说了下区块链的一些东西，比如银行业务，挖矿，发币什么的； 想到了有一次从北京回来，一直带着耳机听哥，入了江西境内才聊和旁边的人了起来，是一位阿里巴巴的大佬，就在公司附近，认识畅游大佬，当时好像问，您缺儿子吗。Jocking. 广东去广东那会正在和Lab聊能不能留国内实习的事情，算是一半可能留下来，一半从深圳飞了。 正巧深圳的同学周末要聚一波，就和罗行、宇哥约了深圳见，先去了下广州。 广州 var ap = new APlayer({ element: document.getElementById(\"aplayer-qJOmlVlb\"), narrow: false, autoplay: false, showlrc: false, music: { title: \"一年前的声音\", author: \"姜姜\", url: \"https://chenmi-ink-1252570167.cos.na-siliconvalley.myqcloud.com/Music/voice.mp3\", pic: \"https://chenmi-ink-1252570167.cos.na-siliconvalley.myqcloud.com/TripGuangzhou.JPG\", lrc: \"\" } }); window.aplayers || (window.aplayers = []); window.aplayers.push(ap); 一如一年之前，入住同一家酒店。 在正佳广场附近走了会，感觉可以在块商区吃一辈子。 晚饭和姜姜在西山居酒屋碰了面，这个名字我喜欢，西山居。 剑三重制版出来后，就是条废牛了，砸了一手水云寒，郭炜炜啊。 听说姜姜也要出去读研，之前以为是美国，后来才发现是香港，一脸不开心。 其实，朋友们都能越来越好，很开心的。 回国前Mike让我多拍些美食回去给他看，姜姜看了一眼照片，大概也是觉着直男拍出来的无法入眼，边吐槽边代劳了。 后来我说，每次听你的声音都有种如沐春风的感觉。她说到，是呀，有很多朋友打电话给我就是听我声音的。 小样。 大脸姜。 深圳Rikki 他们已经在深圳腾讯入职了，组长是个业界大佬，就是知乎上一呼百应你们都知道是谁的那种。 作为广东人，回来以后如鱼得水，舒服。 然后就在车上跟她聊，说到了我要去一个朋友家吃饭，然后我回那个朋友的一句话是，我挑食。 Rikki：你™活该单身一辈子。 去年在深圳约了个小姑娘，本来打算带她和表兄吃个早茶，小姑娘之后没来。 这次就一起吃了个潮汕牛肉，原本计划吃完赶场，没想到人很多，排队吃完已经23点了。 到了坪洲，大部队已经散了，剩下住龙岗的冰月和广斌，说什么也要见上一面，感激。 听冰月说英国留学的事情，果然是每个地方都有不一样的风格，老美这儿还是更加偏自由些。 广斌嘛，就靠你发家致富了。 雨泉和女朋友度蜜月去了，没见上。 宇哥当年打飞的我家里一起做项目，这活最后呵呵了，还是有些亏欠的。 聊以自慰，吃亏是福，贪便宜是失便宜。宇哥，牛奶就少提点把。 罗行可不就是潇潇洒洒万事不愁，羡慕。 第二天看完歌剧后大半夜在街边撸串，喝了点酒，管它几点的飞机，一切如旧。 晚上在酒店，喝晕了的宇哥一回来，抢了我的被子，绝望。 当时想着，有这么一群同学朋友在深圳，隔三差五聚聚吹个逼，也不会寂寞的。 去朋友家里吃饭，既然她做菜，买了点东西过去。 付款的时候，说了句，我来。 她说，你来，不跟你争。 舒服。 嫌弃我切菜，就站在旁边看着七七八八的聊了会。 小学之后就断了联系，也不知道几年前是什么原因，加上我了。 有些事情回想起来，还真是缘分。 离开的时候，吐槽了句，你男朋友要是知道我在背后帮了多少，应该好好谢谢我。 笑。 第一次和帅帅哥哥接触还是毕业以后到深圳工作的那半年，约着吃椰子鸡，当时就很佩服他的习惯。 个人教养果然还是家庭言传身教耳濡目染有关系，高山仰止，景行行止。虽不能至，心向往之。 话剧入场前，打算在附近的咖啡厅坐，路上听到一姐姐打电话骂小三，那一个铮铮铁骨。 刚坐下没多久，一对男女吵架，女人把一杯子水突然泼到旁桌带孩子的妈妈身上，气呼呼的甩门就出去了。那妈妈见势就砸了被子过去。 似乎是无妄之灾，嚷嚷着要录像报警。 大城故事多。 表兄说他买票喜欢买两张，这样有朋友的话，就可以一起去。 然而这样还单着，o(￣▽￣)o。 看完话剧之后，真有点不想离开这里。 结束上了飞机后，左后方坐着一个大块头的老外，中途帮着他说了下要吃啥，挪了下位置。 有趣的是这大块头一直和我飞到了西雅图，也都坐我附近。转机的时候行李都是他帮着拿的。 值机的时候，小姐姐看我转机时间比较紧张，调到了前排的位置，旁边坐着一对夫妇，看孩子毕业典礼的。 在确认了那些特产没法入境后，就开始给周围的人发吃的。后面一群人好像是旅行团，嚷嚷着要把菜单上的酒水都喝一遍。 挺有趣的，空乘小姐姐也笑着说，要不要试试这个，要不要试试那个。 还是海航，好漂亮。","link":"/2018 Trip/"},{"title":"EAE 6320 Engineering II - Assignment 02 Mesh, Effects","text":"This assignment requires us to make a [Mesh] class and a [Effect] class to handle vertices information and shading information separately. Our goal is to support DirectX and OpenGL at the same time and make interfaces for easy use. Since there are differences between these two platforms, we have to decide which part of code is platform specific and make the rest of them become platform independent. Click Download download the game. ProcessIn order to support two platforms, the Graphics.d3d.cpp and Graphics.gl.cpp supports graphic rendering respectively. We keep current structure for cMesh and cEffect class. Use xxx.d3d.cpp, xxx.gl.cpp to handle platform specific codes. Besides, I also add a cMeshData Class as vertex information wrapper. Basically, a vertex would contain different properties such as position, normal, color. This class use a struct that contains multiple sMesh. Right now, the struct only has position property. The cMeshData class is platform independent, so it doesn’t have d3d.cpp or gl.cpp file. 1234struct sVertex { eae6320::Graphics::VertexFormats::sMesh Position;}; In cMeshData : 123456789public: cMeshData(sVertex* vertices, int size); sVertex* vertices; void SetupPositionData(int size); sMesh* GetPositionData(); void ClearPositionData();private: sMesh * position_array = NULL; cMeshIn this assignment, cMesh contains three functions used by Graphics rendering. Because most of the geometry feature is platform specific, these functions are implemented in their platform specific cpp files, cMesh.d3d.cpp, cMesh.gl.cpp The interfaces like below: 123cResult CleanUp();void Draw();cResult InitializeGeometry(); Each Graphic.[platform].cpp has a instance of cMesh like below. 1234// Geometry Data//--------------eae6320::Graphics::cMesh s_mesh_instance; It also contains a cMeshData instance, which contains vertices array data that needs to be rendered on the screen. Right now, we only care about the position. Below are some interfaces: 123VertexFormats::cMeshData m_mesh_data;void CreateMeshData(VertexFormats::sVertex v_data[],int size);unsigned int InitializeMesh(); The implementation of CreateMeshData(//…) ,InitializeMesh() are in cMesh.cpp file. It contains two sMesh arrays for two platforms, which is assigned to CMeshData. The reason to maintain two different arrays is DirectX and OpenGL have different vertices sequence. 1234567891011121314//... VertexFormats:: sVertex vData[vertexCount];#ifdef EAE6320_PLATFORM_D3D vData[0].Position.x = 0.0f; vData[0].Position.y = 0.0f; vData[0].Position.z = 0.0f;#elif EAE6320_PLATFORM_GL vData[0].Position.x = 0.0f; vData[0].Position.y = 0.0f; vData[0].Position.z = 0.0f;#endif //... In this way, each time we change vertices, we only need to make changes in one file. cEffectcEffect also has three functions for Graphic class like cMesh. These are the interfaces: 123eae6320::cResult InitializeShadingData();eae6320::cResult CleanUp();void BindShadingData(); These functions are implemented in cEffect.[platform].cpp . However, some implementation are the same in different platform such as loading shader file, clear shading data. In this assignment, I put these implementations in cEffect.cpp file. 12eae6320::cResult LoadShadingData();eae6320::cResult CleanShaderBase(); Each Graphic.[platform].cpp has a instance of cEffect like below. 123 // Shading Data//-------------eae6320::Graphics::cEffect s_effect_instance; Graphics.[Platform].cppAfter adding implementations of [Mesh] and [Effect] class, both Graphics.[Platform].cpp call these functions to Initialize, Draw, BindShader, CleanUp like below : 12345678// Bind the shading datas_effect_instance.BindShadingData();// Draw the geometry{ s_mesh_instance.Draw();} 12345678910111213141516// Initialize the shading data{ if ( !( result = s_effect_instance.InitializeShadingData())) { EAE6320_ASSERT( false ); goto OnExit; }}// Initialize the geometry{ if (!(result = s_mesh_instance.InitializeGeometry())) { EAE6320_ASSERT(false); goto OnExit; }} 123result = s_mesh_instance.CleanUp();result = s_effect_instance.CleanUp(); Output GPU DebuggerIn this assignment, we need to use analyzers to capture graphic information for a single frame of a running program. We use Visual Studio Graphics Analyzer for DirectX and RenderDoc for OpenGL. DirectX After opening the analyzer, select ClearRenderTargetView(), you would see a black screen. This is because nothing is rendered in this stage. Select the Draw() function and Pipeline stage tab, you could see a single frame like below. OpenGLYou have to download the RenderDoc first and run OpenGL program via RenderDoc. After capturing a frame, select glClear(), you would get a black screen. Then you could see the render target by selecting glDrawArrays(). Finally, You can check triangles by checking the VS input or VS output tab. Thoughts &amp; Discussion In general, both DirectX and OpenGL platforms share the same graphic render pipeline, which makes it possible to use [preprocessor macros] and [modularize pipeline stages] into different files to make Graphics.cpp more platform independent. In order to shrink the codes of graphic renderer pipeline, we separate graphics functions like shading, mesh into cMesh and cEffect. Since their responsibility are more specific, it’s easier to write platform independent implementation. Besides what we implemented in cMesh and cEffects (Initialize,CleanUp,Draw,Bind), we could continue refactor codes from Graphic.[Platform].cpp. It’s possible to merge parts of implementation of [Submitting Data] , [Render Frame Buffer], [Thread] into one file, which makes easier to maintain codes and clear to understand the project. As we can see, the [data format] is different in OpenGL and DirectX including vertice and [symbols]. Besides that, DirectX needs to InitializeViews to setup render target’s properties before rendering buffers. PersonalizeControlsHold [SPACE] key to slow down the color animation. You may see slower animation transition like the images below. (When it becomes dark, it become slower than usual). Output Implementation In Fragment shader, I get vertex position and change color for each section: if(i_position.x&lt;256) rVal=rVal/2+0.5; if(i_position.y&lt;256) bVal =bVal/2+0.5; The picture contains 12 triangles. Here is the vertex data in DirectX: 1234567891011121314151617181920212223242526272829303132333435vData[0].Position.x = 0.0f;vData[0].Position.y = 0.0f;vData[0].Position.z = 0.0f;vData[1].Position.x = 0.0f ;vData[1].Position.y = 0.5f ;vData[1].Position.z = 0.0f ; vData[2].Position.x = 0.5f;vData[2].Position.y = 0.0f;vData[2].Position.z = 0.0f;vData[3].Position.x = 0.0f;vData[3].Position.y = 0.5f;vData[3].Position.z = 0.0f;#pragma region Raw Data//... ...//... ...#pragma endregion vData[33].Position.x = 0.5f;vData[33].Position.y = -0.5f;vData[33].Position.z = 0.0f;vData[34].Position.x = 0.5f;vData[34].Position.y = 0.0f;vData[34].Position.z = 0.0f;vData[35].Position.x = 1.0f;vData[35].Position.y = 0.0f;vData[35].Position.z = 0.0f; This assignment takes me 8 hours to finish. After understanding its main purpose, the main task is to build a stable structure for platforms. DownloadClick Download download the game. Version: x64 - DirectX.","link":"/EAE 6320 Part 02/"},{"title":"EAE 6320 Engineering II -  05 Camera, Rigid-body, Transforms, GameObject","text":"For now, we draw meshes in [Screen Space], in which case we need to calculate each vertex position in a union form range. This is not the way a real game engine deal with dds files. We need add one or more observers into the engine, usually it is camera. To implement: Points We need handle the transforms between different spaces to project objects in [World Space] in to [Screen Space] just like an observer (camera) sees. Rather than calculating each vertex position in world space, we regard a model (set of vertices) as a united object that has its position in [World Space]. This is related to [Model Space] to [World Space] and put meshes and transforms into certain kind of class. Smooth movement control of objects and camera using extrapolate time to reduce “jerky” movement. Click Download the game. ProcessPhysicsI use John-Paul’s Physics Project implement the rigid-body movement. The tricky thing is to decide where to put sRigidBodyState::Update. Like in Unity, the physics related calculation should be called in FixedUpdate which has united time steps. In this project, we set the “logic/fixed/stimulation” timeline as 15 frames and no limits for “rendering/graphics” timeline. Updates Extrapolation is Necessary Right now, two timelines are in application. One is behaved like FixedUpdate() in Unity, One is behaved like Update() in Unity. We cannot guarantee these two functions are always been called in the same time. More often render frames are more than logic frames. The render updates run faster (more calls) than fixed updates. So, each render update calls would use the same position stored in last physic update calls. In this case, the render position doesn’t match what player supposed if the entity is moving. Therefore, we need to submit some future rigid-body information (relatively to “FixedUpdate“ calls) before drawing. Timeline Chart Although the time goes, the render pipeline always uses old position and when next fixed update happens, it will change the position suddenly. The Diagram shows two timelines for updates. sequenceDiagram opt Static In Render Note Left of F_Timeline : Fixed-Update[N] : s_Postion F_Timeline->>R_Timeline : s_Postion @ f_Update[N] Note Right of R_Timeline : Render-Update[N+1]__Accept Data__ F_Timeline->>R_Timeline : s_Postion @ f_Update[N] Note Right of R_Timeline : r_Update([N+2] Note Right of R_Timeline : .... F_Timeline->>R_Timeline : s_Postion @ f_Update[N] Note Right of R_Timeline :r_Update[N+X] end opt Jerky - Suddenly Flash Note Left of F_Timeline :f_Update[N+1] F_Timeline->>R_Timeline : s_Postion @ f_Update[N+1] Note Right of R_Timeline : r_Update[N+X+1] end Note over F_Timeline ,R_Timeline: Add Elapsed Time Movement opt Smooth Note Left of F_Timeline :f_Update[N+1] alt Jerky F_Timeline->>R_Timeline : s_Postion @ f_Update[N+1] else Smooth F_Timeline->>R_Timeline : s_Postion@ f_Update[N+1] +Distance[timeOffest] end Note Right of R_Timeline : r_ Update[N+X+1] end [Fixed Update] 15 calls per second. cGameObjectI create a cGameobject class as representation of entity in the engine. The interface is below:123456789101112131415class cGameObject{ public: cGameObject(); ~cGameObject(); Physics::sRigidBodyState _rigid_body_state; cMesh* m_mesh_instance; cEffect* m_effect_instance; bool isVisable = true; // Functions void LoadRenderInfo(cMesh* meshRef,cEffect* effectRef); //...... }; The cMesh pointer, cEffect pointer works as graphic render property, and sRigidBodyState works as physics property. In this way, the gameobject could track its “Look” and “Body”. It may have more status like “visible” in the future. After having cGameObject, It is cGameObject’s responsibility to submit render data to graphic render thread. like below: 1void SubmitMeshWithEffect(const float i_secondCountToExtrapolate); Since it already has meshs and effects, the only parameter is time offset between “Update“ and “FixedUpdate“ calls, which is used to calculate current render position. Within it: 123void Graphics::SubmitMeshEffectPairs(cMesh *meshInstance, cEffect *effectInstance, Math::cQuaternion rotation,Math::sVector position) cMeshPrefabBesides, I also make a cMeshPrefab class to save vertices and index data. By adding this, the flow works more like loading a model data to instantiate meshes and pass instances to entities. In this way, the cGameobject would only modify its own mesh like scale or morph and keep original data clean. To initialize, LoadExternalData : 123cMeshPrefab::LoadExternalData(std::vector&lt;VertexFormats::sMesh&gt; vertice,std::vector&lt;uint16_t&gt; indexArray) To create mesh instance form a prefab and assign to gameobject: 12result = Graphics::cMesh::MeshFactory(s_Pyramid_Mesh.GetMeshData(),s_Pyramid_Mesh.GetIndexData(), s_mesh_instance2); sPerDrawCallFor each meshes, it has a perDrawcall buffer used as passing data from CPU to GPU. The sPerDrawCall buffer has a g_transform_localToWorld transform. To calculate it, I pass acQuaternion (4 floats) and a sVector (3 floats). Totally, the graphics only need to know 7 floats for each gameobject per drawcall . Size of Drawcall Platform Size DirecX 16+12 -&gt; 28 OpenGL 16+12 -&gt; 28 Thoughts &amp; Discussion I decide not to add a Transform class to cGameObject this time since sRigidBodyState has position and quaternion, which are smaller than a matrix. Another reason is that, right now, we only need to calculate the matrix per draw call once in graphic. I think it’s hard to determine the balance between time and memory size in game engine because the lack of enough experience and use cases. In game development, we are more likely to sacrifice more memory (reasonable) to reduce waiting time. PersonalizeControlsHold [SPACE] key to slow down the color animation. Hold [Shift] key to hide the square in the center. Hold [Ctrl] key to change four triangles color. Press [↑, ↓, ←, →] keys to move around camera. Press [Q],[E],[Z],[C] keys to rotate camera left, right, up and down. Press [A],[S],[D],[W] keys to move around default gameobject. Press [1],[2] keys to switch default gameobject’s mesh. [1] -&gt; Square; [2] -&gt; Pyramid Screen ShotsKeys show on the left corner with input count. Movement Change Mesh Implementation cCamera To allow camera move along it’s facing axes, we have to get camera’s directions. It’s better to let cCamera caches a cMatrix_transformation which updates in “FixedUpdate“ in UpdateRigidbody. 12345678910public: void SubmitCameraInfo(const float i_elapsedSecond_sinceLastUpdate); void UpdateRigidbody(const float i_elapsedSecond_sinceLastUpdate); Physics::sRigidBodyState s_rigid_body_state; Math::cMatrix_transformation s_transformation;//Camera Configs - FOV//.....private: void UpdateMatrix(); Shader With different mesh’s “local-position.z” value, I assign different values to “blue channel”. So in Pyramid mesh, there is section in different color. We pass “local-vertex-position” from Vertex shader to Fragment shader. Then in Fragment shader: In D3D: 1234in const float3 o_position : POSITION,//...if(o_position.z&lt;0) bVal=0;//... In OpenGL: 1234in float depthZ;//...if(depthZ&lt;0) bVal=0;//... Camera Movement Download Click Download the game. Version: x64 - DirectX.","link":"/EAE 6320 Write-up 05/"},{"title":"EAE 6320  - Game System Review - Animator and Animation Controller","text":"SummaryCurrent animation system support: Animate Gameobject position and rotation in key frames. Multiple animation clips and switch flow. Simple animation controller. Binary data file driven. AnimationAnimation ClipOne animation clip contains several keyframes. Each KeyFrame contain keytime, position and rotation. Generally, the animation clip we defined look like following picture: The picture shows a clip called “New Animation” which has four keyframes. Between each keyframe, there would be lerp curve to change the value by time. Like below: Currently in animation system, I’ve implemented linear lerp for rotation and position. Besides, to support PlayClip(string i_name) function, we also store each clip’s duration and Name. Key FrameKey frame structure: 123456struct KeyFrame { float time=0.0; Math::sVector position; Math::cQuaternion rotation; }; cGameObjectAnimation (Animator)cGameObjectAnimation contains several animations and transitions between clips. It works more like an Animator in Unity. In cGameObjectAnimation, it offers several functions for user to bind, control, switch animation clips and has internal functions to update the animation by frames. KeyFunction 123456789- Binds(cGameObject i_object) // [Assign GameObject be animated]- Play()- Stop()- PlayClips(int index)- PlayClips(string clipName)- SetSpeed(float speed) // [1 is default.]- Loop(bool isLoop)- SetInt(string conditionName, int conditionValue). // [used for set transition condition like in Unity] Internal123- Update(float deltaTime) // [Update Animations Time]- UpdateObject(float deltaTime) // [calculations and switch keyframes]- CheckConditions() // [Determine transitions] Explanation cType: [TRIGGER,INT,FLOAT,BOOL]; ConditionName: Use the name to assign value for transistion. Relation: 3 relations for number values. Equal,Greater,Less. HasEnd: Whether wait for the end of current animation Animation TableHuman Readable File Duration List Clip Names List Transition Condition List Clip List - Key Frame List Each Condition cType [condition Type: TRIGGER,INT,FLOAT,BOOL] CName [condition Name: STRING] Condition Parameters [from clip idx, to clip idx, traget value, relation,hasEnd] TransitionsIn the example, we have four animation clips and below is conditions. 1234567891011121314151617181920212223242526272829303132333435Conditions={ { ctype=1, cName=\"RCondition\", -- From, -- To, -- TargetVal, -- Relation : 1 = Greater; 0 = Equals; -1 = Less -- HasEnd : 1 = YES; 0 = NO; condition={1,0,3,0,1} }, { ctype=1, cName=\"MCondition\", -- From, To,TargetVal,Relation -- Relation : 1 = Greater; 0 = Equals; -1 = Less condition={0,1,1,0,1} }, { ctype=1, cName=\"MCondition\", -- From, To,TargetVal,Relation -- Relation : 1 = Greater; 0 = Equals; -1 = Less condition={0,2,2,0,0} }, { ctype=1, cName=\"MCondition\", -- From, To,TargetVal,Relation -- Relation : 1 = Greater; 0 = Equals; -1 = Less condition={0,3,9,1,0} },}, Transitions Graph In the example setting, we can change MConditions value to make transitions. anim.SetInt(&quot;MCondition&quot;,1) switch clip to [1] animation - RotY. Each KeyFrame kTime [KeyTime] position [x,y,z] rotation [w,x,y,z] Data FileBelow is the testing example 4 clips with 4 key frames each; 4 transition conditions; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869return{Duration={5.0,10.0,5.0,8.0},ClipsNames={\"MoveUp\",\"RotY\",\"RotZ\",\"Combine\"},Conditions={ { ctype=1, cName=\"MCondition\", -- From, -- To, -- TargetVal, -- Relation : 1 = Greater; 0 = Equals; -1 = Less -- HasEnd : 1 = YES; 0 = NO; condition={0,1,3,0,1} }, {-- condition -2 }, {-- condition -3 }, { ctype=1, cName=\"MCondition\", -- Relation : 1 = Greater; 0 = Equals; -1 = Less condition={0,3,9,1,0} },},Clips={ { -- Clip - 1 { kTime=0.0, position={1.2,0.0,0.7}, rotation={1,0,0,0}, }, { -- keyframe 2 }, { -- keyframe 3 }, { -- keyframe 4 }, }, { -- Clip - 2 { -- keyframe 0 }, { kTime=8.0, position={1.2,1.0,0.7}, rotation={-0.707,0,-0.707,0}, }, { -- keyframe 3 }, { -- keyframe 4 }, },},} Explanation kTime : the time of the keyframe. You should keep it starts from 0 and ends at the duration for correct display. rotation: currently it stores data in Quaternion. I may make a Vector-&gt;Quaternion function for a better use. Animation BuilderIt’s like other Builder projects under Tools folder. To use that, you need to add types in AssetsToBuild and add functions like before, write binary files into Data. Binary DataThe Order Clips Count - uint16_t Time Array (in seconds) - Float Array Name Array - String Array ==Loop for Clips Count== Keys Count - uint16_t KeyFrame Array - KeyFrame ==End== ==Loop for Clips Count== Condition Count - uint16_t Condition Array - ConditionPair ==End== cGameObjectInitializeRight now, in LoadRenderInfo, it pass the cGameobjectAnimation to the gameobject. Inside, it binds the animation and play it as default. In cMyGame::Initialize(), you can load the animation table and initialize the instance.123//Load Animationc_test_animation.LoadAsset(&quot;data/animations/testanimation.lua&quot;); Then, in your gameobject initialize function, pass the instance and bind. 12345if(c_animation) { anim = *c_animation; anim.Binds(this); } UsesIn cMyGame, put all animation instances inside the Update(seconds) function and update them. Access cGameObjectAnimation and use related functions to control the Animation. Like below: 12345678910111213141516171819202122232425// Animation Ctrl //Stop { s_movable_game_object-&gt;anim.stop(); } //change Loop { s_movable_game_object-&gt;anim.loop(true); } //change Speed { s_movable_game_object-&gt;anim.setSpeed(10); } //Play By Name { s_movable_game_object-&gt;anim.playClip(\"RotZ\"); }// Condition Ctrl { s_movable_game_object-&gt;anim.SetInt(\"MCondition\",1); } ChangesAdd Projects Add Animation Project into Engine; Add AnimationBuilder Project into Tools; Add Lerp Math Add two math function for Rotation Lerp in cQuaternion; Add Assets Hanlder In AssetsToBuild.lua, add new type as following 1234animations ={ { path = \"Animations/testAnimation.lua\"},}, In AssetsBuildFunctions.lua, add functions 12345678910111213NewAssetTypeInfo( \"animations\", { ConvertSourceRelativePathToBuiltRelativePath = function( i_sourceRelativePath ) -- Change the source file extension to the binary version local relativeDirectory, file = i_sourceRelativePath:match( \"(.-)([^/\\\\]+)$\" ) local fileName, extensionWithPeriod = file:match( \"([^%.]+)(.*)\" ) return relativeDirectory .. fileName .. extensionWithPeriod end, GetBuilderRelativePath = function() return \"AnimationBuilder.exe\" end }) InitializeYou can initialize the Aniamtion Instance just like cMesh instance or cEffects instance. Depend on the way you want to implement, you can let cGameObject has a reference of cGameobejctAnimation. Or put somewhere you like. If you add a reference in GameObject, you can update like below1selectedGameobject-&gt;UpdateAniamtion(i_elapsedSecondCount_sinceLastUpdate); PersonalizeControlsHold [SPACE] key to slow down the color animation. Hold [Shift] key to hide the square in the center. Hold [Ctrl] key to change four triangles color. Press [↑, ↓, ←, →] keys to move around camera. Press [Q],[E],[Z],[C] keys to rotate camera left, right, up and down. Press [A],[S],[D],[W] keys to move around default gameobject. Press [1],[2] keys to switch default gameobject’s mesh. [1] -&gt; Teapot; [2] -&gt; Circle Press [7],[8],[9],[0] keys to play animation clips by name. [MoveUp,RotY,RotZ,Combine] Press [J],[K],[L] keys to play animation using conditions . Press [P],[O],[U],[Y],[I] keys to stop, play, loop, disable loop, change speed in animation. Screen Shots DownloadAnimation Project Click Download the game. Game Click Download the game. Version: x64 - DirectX.","link":"/EAE 6320 Write-up 13/"},{"title":"EAE 6900 Game AI - Steering Behaviors","text":"SummaryThis writeup is a review of the first project in game AI class. This project contains a variety of steering behaviors including seeking, wandering, collision, flocking, which explores how to blend different simple behaviors to work out a complex, realistic simulation. The project is based on openFrameworks. It contains four parts including kinematic movement, arriving behavior, wandering behavior and flocking simulation with collision detection. I spent much time making all behaviors realistic enough, which is not easy. I get a further understanding of the way simple behavior parameters can contribute to the final results. The flocking simulation is a good example, which is blended by alignment, separation, wandering, and collision. Besides that, some implementation from class is not accurate and need to make changes to fit in your architecture. Behavioral simulationThe primary purpose of the simulation is to calculate and updates each unit kinematic properties and use them to create movement. The movement is reflected by position and rotation in the game. Our AI algorithm’s job is to output factors or steering force, which are used to update kinematic properties. Dynamic and KinematicThere are two different factor pairs we can use to updates unit’s position and rotation as steering force. One is called kinematic steering, which directly changes velocity and angular speed. Inside the unit, it will add the steering results during each frame. The other way is called dynamic steering, which uses acceleration. Although they have different updates calculation and slight difference, both methods are robust for a game to create a realistic behavioral simulation. CombinationTo create combination behavior, the simplest way is to add all steering force and keep them to limits such as max speed, max acceleration. In a more complicated situation, for example, there is avoiding behavior that we should not move towards an obstacle and pass it. Just adding outputs is not able to create correct results in this case. One way we can use is to assign each behavior a weighted value. When combining these behaviors, we multiply the force with the value. Project ArchitectureMain FlowThe ofApp class maintains the game loop flow. It has four Motion class relates to four behaviors we created. Each Motion has Init,Update,Draw,OnMousePress states functions which fit into the main game loop. Besides functions, it also has several steering behaviors, which are our AI algorithm, as well as units objects to be rendered. The Motion class is defined like below. 123456789101112131415161718class Motion{//.... void Init(); void Update(); void Draw(); void OnMousePressed(int x,int y, int button); DynamicArrive arrive; DynamicAlign align; //... Boid m_boid; Rigidbody targetRigid;}; Steering ModelGenerally, the project contains two types of steering behavior base class. One is called DynamicSteering, the other is called KinematicSteering.All individual behaviors like seeking, wandering, arriving is child class of these two class. They all have a virtual function called getSteering. This function will be overridden by different individual behaviors class and give the steering force as output. As I mentioned above, the output from these two steering behavior is different. For example, the output fromKinematicSteering behavior would only change Velocity or Rotation. 123456789class DynamicArrive : public DynamicSteering{public: float timeToTarget; float TargetRadius; float slowRadius; virtual void getSteering(SteeringOutput* output) ;}; CalculationAfter setting up steering behaviors, the Motion class would take steering data as input and Updates based on the behavior. 123456789auto deltaTime = ofGetLastFrameTime();SteeringOutput steer;arrive.getSteering(&amp;steer);targetRigid.Orientation = align.character-&gt;GetMovementOrientation();align.getSteering(&amp;steer);m_boid.Update(steer, deltaTime); Individual BehaviorKinematic MotionIn this motion, the unit only goes around the edges. I just assigned an initial velocity to the unit. The most tricky thing is to use openFrameworks to rotate the shape in its own space. I think this part is good for us to get familiar with openFrameworks. Below is the results. Seek Steering BehaviorsContent Seek location of mouse clicks. Oriented the direction of travel In this motion, I used DynamicSeek,DynamicArrive, DynamicAlign, LookToMovement combining them together testing. Below is the DynamicArrive with DynamicAlign. Introduction Analysis &amp; Thoughts There is a tiny issue in the implementation we covered during class. When a unit is about to reach the target, if we do nothing with the steering force, it will not stop. For movement : DynamicArrive is more realistic, which will slow down the speed significantly when reaching the target. It suits for smooth movement and realistic physics simulation. KinematicArrive would let unit directly stop when reaching the target. It is not good for common movement or physic simulation. But for games design, it is still good enough to control objects. For rotation: LookToMovement creates more realistic visual effects. It always gives you correct and stable rotation, which is based on current velocity. In our implementation, velocity is gradually calculated by steering force, therefore, just updates the orientation after setting the velocity. DynamicAlign : need some time to slow down the angular speed and its target radius still has a small range, it may cause some delay depending on different parameters you set to the align Behavior. You may find the rotation delay and the unit cannot stop in following clip. It uses DynamicArrive&amp;DynamicAlign. Below is the combination of DynamicArrive &amp; LookToMovement. You can modify max acceleration to get smoother movement. Wander Steering BehaviorsIntroductionThe key is to get a small rotation based on current orientation. We use unified BinomialRandom to get random results. The results have more chances to be around 0. By multiple rotation factors, we can get a wandering rotation. There are two ways to implement wander behaviors. First is to find a target within a specific direction, then seek that target. Second is to change a rotation with a small range first and move forward. Analysis &amp; Thoughts I’ve tried these two ways to wander behaviors. I think both methods can create same quality by changing parameters. The most important factor creating different movement path is orientation offset. Also, I tried a kinematic and dynamic way to change the movements. The dynamic steering has a better look. However, I think it is because of the parameters. Flocking BehaviorsBlenderFlocking is a combination behavior. This project uses weighted behavior to create the combination. Each behavior has a default weighted value. Certains Steering behavior may change the weighted value in one frame and restore to default values at the end of the frames. For instance, the AvoidCollision behavior would raise its weighted value if the unit enters the detection area. See the picture below. For blending all steering forces. In FockMotion, the Update method hold different kinds of steerings at the beginning and accumulate together at the end of the function. 1234567891011//for each unit in the flock// .... Calculation SteeringOutput steering_output; steering_output.linear += seek_output.linear* (flock.boid_list[i].mRigidbody.wSeek) ; steering_output.linear += avoid_output.linear*(flock.boid_list[i].mRigidbody.wAvo) ; steering_output.linear += sep_output.linear*(flock.boid_list[i].mRigidbody.wSep) ; steering_output.linear += wander_output.linear*(flock.boid_list[i].mRigidbody.wWan) ; //.... flock.boid_list[i].Update(steering_output, ofGetLastFrameTime()); The unit would reset its weight values into default setting after changing current movement data. 12345mRigidbody.Update(steer,deltaTime);//Check limits ...UpdateWeight(); Flock Flocking behavior needs separation, align and cohesion. I only implement separation and velocity match behavior for this project. Theoretically, we need to implement cohesion behavior. One of the project requirements is to seek the center of the flock. It is how cohesion defines. These rules are summarized as follows:Cohesion: Have each unit steer toward the average position of its neighbors. Alignment: Have each unit steer to align itself to the average heading of its neighbors. Separation: Have each unit steer to avoid hitting its neighbors. You could also change the cohesion / seek center by left or right click the unit — the effects as below. The first video set avoid weight value lower. You can find that units are easy to pass the blue obstacles. The second video has a higher weight value. You can find that units are hard to pass the blue obstacles. Collision Detection: I also create collision detection for the flocking behavior. Each unit has its own specific radius checking collision. If it’s heading toward the object, calculate a steering force that will lead the agent around or away from the obstacle based on its current velocity, position, and directing. Basic Implementation as below 123456789101112131415161718192021222324252627282930// If in collision detection { // Change the weight character-&gt;wAvo= 200.0f; character-&gt;wWan = 0.1f; // If in collision { //Flee } else { //if move towards the obstacle { if (abs(character-&gt;Velocity.x) &lt;= abs(character-&gt;Velocity.y)) { // deal in vertical direction output-&gt;linear = ofVec2f((character-&gt;Position.x - element.mRigidbody.Position.x), character-&gt;Velocity.y); output-&gt;linear = output-&gt;linear.getNormalized()*(50*((bound) / dist)); } else { // deal in horizontal direction output-&gt;linear = ofVec2f(character-&gt;Velocity.x, (character-&gt;Position.y - element.mRigidbody.Position.y)); output-&gt;linear = output-&gt;linear.getNormalized()*(50*((bound) / dist)); } } } } Analysis &amp; Thoughts After making all units seek two leaders, it turns out that units will finally form into two groups. It is essential to set weighted value correctly to get a realistic flock behavior. Different values may get different results. Balancing values and scaling factors is not convinient for current project. In the beginning, I set the separation scale factor too small, and there is no align steering force. Since it has cohesion at the same time, separation steering forces are influenced by cohesion force. All units are get together around the same point. After adding factor value and change the weighted value of separation steering force, It becomes realistic immediately. The collision steering force needs to have a higher weighted value to get a higher priority effect. If the value is too small, some units will move into the obstacle and return. ControlsPress [q] -&gt; Basic Motion; Press [w] -&gt; Seek Motion; Press [e] -&gt; Wander Motion; Press [r] -&gt; Flock Motion; In Seek Motion, Click to set a location. In Flock Motion, left click to set LeaderA; right click to set LeaderB. Future Improvements in Steering Because we need to change values frequently to get a better look for AI, It would be better to integrate UI controller system into the project. Polishing structure and simulation result. References Reynolds, C. W. (1999) Steering Behaviors For Autonomous Characters, in the proceedings of Game Developers Conference 1999 held in San Jose, California. Miller Freeman Game Group, San Francisco, California. Pages 763-782. https://www.red3d.com/cwr/steer/gdc99/ Ian Millington and John Funge. 2009. Artificial Intelligence for Games, Second Edition (2nd ed.). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.","link":"/EAE 6900 AI Write-up 01/"},{"title":"EAE 6900 Game AI - Pathfinding","text":"SummaryThis writeup is a report of study research in pathfinding. It covers the following sections. Representing the real world in a graph; Dijkstra’s Algorithm, A* Pathfinding Heuristic search Steer Integration The project is based on openFrameworks and contains several demos that help explain related analytic. For this part, the project now includes the following features. Map generator. It generates a graph from pictures. One is simpler size, the other is from Google Map. Pathfinding Visualization Editor. It contains implementation of Dijkstra, A* pathfinding algorithm. The demo also supports different heuristic search setting and performance report. It also has a map editor, in which you can set start node, destination node as well as obstacle node. The integration of steer behavior from the last project. AI ModelIn the class, we built a model for our game AI, in which, the pathfinding is between decision making and movement. Just as the picture shows, the Pathfinder is used simply to work out where to move to reach a goal. To move an entity along a path route in the game, we need to integrate the movement system. This is what we have built in the last update. Input: Graph search algorithms, including A , take a “graph” as input. A graph is a set of locations (“nodes”) and the connections (“edges”) between them. Here’s the graph I gave to A: World RepresentationsQuantization and LocalizationTo begin, we can use a directed non-negative weighted graph to represent a level. The graph contains a set of nodes and connections. Depending on the implementation, the node or the connection has a weighted value as movement cost. Then pathfinding algorithms use this graph to calculate movement cost for each node. After calculation, it successfully finds a path; it would return a list of nodes that are connected to form a path. However, this is the only conceptual assumption, and real games not only have nodes and connection in the level. Therefore, we need to do some modifications to the level so that the Pathfinder can analyze map data. As we know, many RTS games use tile-based graphs extensively. In this project, I’ve implemented a world representation by using tile graphs. Structure &amp; ImplementationStructure &amp; ImplementationThe map representation part has a Cell class as a Node in a weighted graph. It has some variables used by pathfinder algorithm such as cost, known the cost, estimation cost.12345ofPtr&lt;Cell&gt;parent;ofVec2f pos; //Tile Index ofVec2f worldPos; // Screen Positionfloat cost = 1; // Weighted Valuefloat estimate=0, known=0, total=0; Then we create a TileMap class. It contains a list of cells (nodes) and some util methods used by pathfinder algorithm. 123456ofPtr&lt;Cell&gt;&amp; GetNode(int x, int y);std::vector&lt;ofPtr&lt;Cell&gt;&gt; NodeList;float width;float height; To set up a map, I implemented it in two ways. The first is to set up a map editor simply by rows and columns. It will split the screen into cells. By default, the weighted value is defined by the geometry information. 1void Setup(int col,int row); The other way is to read pixel brightness from an image. By storing the geometry data into a picture, it will contain detailed information. 12345678910111213141516void Setup(ofPixels&amp; pix);{ //.... // Use Briteness as cost float brightness = pix.getColor(x, y).getBrightness() / 255.; if (brightness &lt; 0.85) { GetNode(x, y)-&gt;SetCost(0); } else if (brightness &lt; 1.) { GetNode(x, y)-&gt;SetCost(1. / brightness); }//....} Simple Node MapIn the project, the simple node map is based on the picture below. Since we will check the briteness, only white area are connected, which would be considered to be walkable. In the game , it may represent a map like this. We could also just define unwalkable area using the same map as below, which gives more area to move around in the game. After we convert it into grids. The tile map structure that pathfinder use to compute look like this. VideoYou could watch this video to check all the other maps and how the editor works. Pathfinding AlgorithmDijkstraDijkstra The structure of this algorithm is very similar to the Prim algorithm, which uses a priority queue for traversal. In the Dijkstra algorithm, the priority is a distance value estimate. Implementation 1234567891011def dijkstra(G, s): D, P, Q, S = {s: 0}, {}, [(0, s)], set() while Q: _, u = heappop(Q) if u in S: continue S.add(u) for v in G[u]: relax(G, u, v, D, P) heappush(Q, (D[v], v)) return D, P A*A algorithm The A algorithm is a bit like the concept of heuristic search in artificial intelligence. Rather than blindly searching like DFS and BFS. Nor does it know nothing about the future direction like the Dijkstra algorithm. Because A adds a potential function, it can also be called the heuristic function h(v). 1w&apos;(u, v) = w(u, v) - h(u) + h(v) Then you will find that after this adjustment, the algorithm has a preference for the low-cost edge (node). The A* algorithm is equivalent to the Dijkstra algorithm for the modified graph. If his feasible, the algorithm is correct. Implementation 12345678910111213def a_star(G, s, t, h): P, Q = dict(), [(h(s), None, s)] while Q: d, p, u = heappop(Q) if u in P: continue P[u] = p if u == t: return d - h(t), P for v in G[u]: w = G[u][v] - h(u) + h(v) heappush(Q, (d + w, u, v)) return inf, None The running time of this algorithm is Q((mn)lgn), where m is the number of edges and n is the number of nodes. Analysis &amp; ThoughtsProject Support The Dijkstra’s algorithm spends more time, visits more nodes than A Star algorithm. It is greedy not motion planning. You can see the difference between these two algorithms. (Especially when getting to the end point.) When using Dijkstra’s algorithm, the visited nodes in Maze are like below: When using A Star algorithm, the visited nodes in Maze are like below: Thoughts A* is a single source single destination algorithm, its time complexity is O(|E|), E is the number of all the edges in the path. In other words, A can be used to calculate the optimal path from one point to another. This also means that A is suitable for path calculation of the dynamic environment, and the path can be calculated immediately according to the current environment. Correspondingly, Dijkstra’s algorithm and Floyd-Warshall are suitable for calculations in a constant environment. Given a point on the map, Dijkstra can be used to calculate the optimal path for all other path points on the map at one time. Dijkstra’s time complexity is O(|E|+|V|log|V|), where E is the number of edges and V is the number of a vertex. From above we can tell that if you need to calculate the left and right paths for all the points on the map at the same time, Dijkstra will be more convenient than using A*. This also explains why Dijkstra is suitable for computing in a static environment because the static environment will not change. Generally A* search: single source single destination, which is faster but depends on the design of the heuristic function. Suitable for RTS in dynamic environments. Dijkstra’s Algorithm: single source all destinations, the speed is also faster, no heuristic function is needed, but backtrack is required when creating the navigation table. Pathfinding for static environments. HeuristicsImplementation12345678910111213141516171819202122 switch (ofApp::HeuristicsType) { case 0: this-&gt;estimate = dx + dy; break; case 1: this-&gt;estimate = max(dx, dy); break; case 2: this-&gt;estimate = sqrt(dx * dx + dy * dy); break; case 3: this-&gt;estimate = abs(dx - dy) + sqrt(2) * MIN(dx, dy);; break; case 4: float F = sqrt(2) - 1; this-&gt;estimate=(dx &lt; dy) ? F * dx + dy : F * dy + dx; break; } this-&gt;estimate*=ofApp::hWeight;} Result Analysis The heuristic function h(n) tells A* an estimate of the minimum cost from any vertex n to the goal. It’s important to choose a good heuristic function. If h(n) is sometimes greater than the cost of moving from n to the goal, then A* is not guaranteed to find a shortest path, but it can run faster. At the other extreme, if h(n) is very high relative to g(n), then only h(n) plays a role, and A* turns into Greedy Best-First-Search. Manhattan distance 1H(n) = D * (abs ( n.x – goal.x ) + abs ( n.y – goal.y ) ) Diagonal distance 1h(n) = D * max(abs(n.x - goal.x), abs(n.y - goal.y)) Euclidean distance 1234function heuristic(node) = dx = abs(node.x - goal.x) dy = abs(node.y - goal.y) return D * sqrt(dx * dx + dy * dy) SteerPathfollowingIn order to navigate thought the path, we need to make the boid move from node to node until it reaches the end of the route. Every point in the path can be seen as a target, so the seek and arrive behavior can be used. The following function defined as below: 12345678class Follow : public Steering{public: std::vector&lt;ofPtr&lt;Cell&gt; &gt; path; float pRadius; int curIdx; virtual void getSteering(SteeringOutput* output);}; The implementation is quite simple. It will go through the nodes one by one and call Arrive behavior.12345678910111213141516if (character-&gt;Position.distance(targetNode-&gt;worldPos) &lt; pRadius){ if (curIdx &lt; path.size() - 1) { curIdx++; }//....} if (curIdx &lt;= path.size() - 1){ DynamicArrive arrive; //... arrive.targetPosition = path[path.size() - curIdx - 1]-&gt;worldPos; arrive.getSteering(output);} Analysis When the node become too small like one pixel, the parameters of following behavior need to be precisely set . It may cause the boid move around or back and force when the velocity and range is too large while the cell range is too small. CollisionI also create collision detection for the flocking behavior. Each unit has its own specific radius checking collision. If it’s heading toward the object, calculate a steering force that will lead the agent around or away from the obstacle based on its current velocity, position, and directing. Basic Implementation as below 1234567891011121314151617181920212223// If in collision detection { // Change the weight // If in collision //Flee else { //if move towards the obstacle { if (abs(character-&gt;Velocity.x) &lt;= abs(character-&gt;Velocity.y)) { // deal in vertical direction output-&gt;linear = ofVec2f((character-&gt;Position.x - element.mRigidbody.Position.x), character-&gt;Velocity.y); output-&gt;linear = output-&gt;linear.getNormalized()*(50*((bound) / dist)); } else { // deal in horizontal direction output-&gt;linear = ofVec2f(character-&gt;Velocity.x, (character-&gt;Position.y - element.mRigidbody.Position.y)); output-&gt;linear = output-&gt;linear.getNormalized()*(50*((bound) / dist)); } } } } Video Install Add ofxDatGui Project. Download: https://github.com/braitsch/ofxDatGui. Copy entire ofxDatGui project into your OpenFrameswork folder. The path is OpenFrameswork/addons/ofxDatGui Use projectGenerator-vs/projectGenerator.exe to Import the GameAIproject. You should see the Addons section has the ofxDatGui. Click Update and Open IDE. Control Use the GUI to change the parameters. Algorithm Dropdown: switch Dijkstra’s or A Star. Map Dropdown: switch editor mode or maps. Editor rows/columns: change cell number in editor mode. Image Dropdown: show nodes or original picture Heuristics Dropdown: switch heuristic calculation Show Boid: whether show the boid in A star mode. Reload Button: Refresh the map. Run Path Finding (Press[R]): Calculate path; In editor mode: Pressing Left Button: Drag Start Point. Pressing Right Button: Drag End Point. Pressing Left Button and Pressing [Z]: Put Obstacle Nodes. (Choose “Show Unwalkable Area” to be visible) Download Click Download the project. References Reynolds, C. W. (1999) Steering Behaviors For Autonomous Characters, in the proceedings of Game Developers Conference 1999 held in San Jose, California. Miller Freeman Game Group, San Francisco, California. Pages 763-782. https://www.red3d.com/cwr/steer/gdc99/ Ian Millington and John Funge. 2009. Artificial Intelligence for Games, Second Edition (2nd ed.). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA. Red Blob Games, Heuristics, http://theory.stanford.edu/~amitp/GameProgramming/Heuristics.html","link":"/EAE 6900 AI Write-up 02/"},{"title":"在美国，三两事","text":"传闻美联航的伙食很差，起了个大早后吃了两小桶泡面备着十几个小时的旅程。因为就住在机场里，到T2也就七八分钟，完成值机后陪着爸妈在机场走了会，合影留念，嘱咐了几句下午在上海的行程，挥了挥手就进了安检通道。从高中开始就在外地生活，这会儿倒没有很多莫名的滋味。 机场临行前看了一堆出入境的攻略，还屁颠颠的在APP里选好了绝佳位置，机身变窄的拐角处，空间舒适度提升了不是一星半点。在出关的时候想起了《Closer》 Alice回国的那句台词，哦，原来就是这样~ 懵懵懂懂上了机，一个亚洲面相的乘务员说了句 Hello Sir， 含糊不清的回了句Hi，那一瞬就明悟了接下来肯定会有一段交流障碍期。 飞机斜向上离开地面飞入云中，看着窗外渐渐变小的房屋，那一瞬鼻子突然很酸，眼睛胀胀的。 远行，游子，异乡。 在云端快速收拾下情绪，戴上耳机开始了接下来十几个小时的旅程。原本在经过日本的时候可以鸟瞰富士山，那天正巧撞上日本上空有台风，算是个小小的遗憾。对我这种糙汉子来说，飞机餐并没差到哪去，虽然嘴挑0.0。 旁边正巧坐了一位华人，吃完第一餐之后我俩就开始聊了起来。 大叔（希望不会介意这个称呼）在Oracle工作，得知我是去学游戏开发后，说EA就在Oracle旁边，或许以后有机会能成为邻居在那块呆一阵~ 大叔人超棒，跟我讲了一些美国呀，SLC呀的情况，申报单怎么写啥的，终归有个老司机在旁边会放心很多。后来大家扯了扯中美一些发展的状况，嘛，最后留微信的时研究下了我的名字。哈哈哈，这一趟旅程下来远比想象的要有趣的多。 Very Enjoyable Chatting! 西海岸上一次见到吴伯伯还是六年前的春节前后，那一句对C语言的”Shit”真滴是当头一棒把我从温水中拍醒了。现在再回想起大学这几年在学校的经历，嗨吖，还真的有点后怕如果按照当时自己洋洋自得的发展，我会变得多么无趣，也就见不到世界上那么多有意思的人，接触到这么多有意思的事情。 去伯伯家的一路上，听着他讲述三十年前刚来美国的情况，一共只有50美元，35美元是报名费，揣着15美元不知道去哪，只知道自己到了美国，然后，，然后就没有然后了。飞机上的大叔因为行李超重也没有余钱付款而在机场耗着等海关换人放他通行，似乎那个年代的人真是和他们说的一样，都是别人靠他们，他们靠的是自己。这或许是他们能够留下来，能够成为大佬的原因之一。 嗯，听着大佬讲述自己的故事也能感受到很多东西。 途中，吴伯伯突然说了一句，你看这一路上都没有喇叭声音。这让我一惊，留意起来，来美国一周的时间，没有听到过有任何的汽车喇叭声音。 很多时候车主都会互相给对方让路，善意的在对面的车窗里示意着手，没有感受到人心浮躁。 第二天下午去了UC Berkeley。伯伯全家都从那毕业的，又是CS名校，带我去感受感受美国校园的气氛。走在一处文化墙附近，刚准备拍照，正巧旁边经过一个白人长发小哥，他回头说了句 “你好”，继续向前走了过去。旁边伯母听到后回了句，而我还很懵逼的思考发生了啥。 如此随性，如此舒服。 Life is a box of chocolates! 边走着伯母说，在Berkeley最有厉害的是有一个专属停车位。学校专门划出一块地方做专属停车位，而获得这个车位的资格就是，拿到诺贝尔奖。嗯，厉害了。 准备去费城的那天，他们带我到旧金山繁华的地方转了转，去了唐人街，看了下加州市政府，在机场附近的一个中餐馆吃到了比国内还好吃的中餐，酒香不怕巷子深。 这一看终于明白了他们小儿子回宜春看到的宜春市政府大楼后，为啥一脸不可思议的问，这不是中国比较穷的地方吗？ 中国的现代化发展的越来越好了，或许真是缺少什么就珍惜什么，美国没多少年的历史对自己的历史传承特别看重，就喜欢那些旧房子。政府拿了税后，人民说不让你拆就不能拆。嗨吖，在繁华的地段看到有一小块小广场，旁边随意坐着半躺着各种各样的人，这要是在国内，估计就是破坏市容的级别啦。 从山上鸟瞰旧金山湾区的感觉，棒。 东部旧金山到费城时差三个小时，妥妥的破灭了我飞机上调时差的计划。在机场候机，何老板问美国的空气好闻吗，正巧从Drinking Foundation那接了一杯水，喝了一口后回消息：水都更甜。 下了飞机姨父姨妈接我到家里去休息，这一睡就十几个小时到了第二天早上。姨妈非常热心，还在国内的时候就嘱咐了我很多事情，特地准备了一个大箱子，装了很多东西。尴尬的发现，似乎我这种瘦小的身材在美国很难买到合适的裤子，只能尝试童装了- -…. 之后去办了银行卡，柜台白人小哥人超级Nice，东拉西扯的聊了很多，得知我要去学EAE，说到第一次听说Engineering里也有Art的。哼唧，所以说做游戏的Coder都是Artist。后来小哥说他自己九月份也要去学语言了，读研究生，Congratulations! 伯伯和姨妈家里都是吃中餐，又或者是觉着我以后可能很难吃到中餐了，所以一直不嫌麻烦的准备中餐，直到后来跟姨妈出去到外面吃了牛肉汉堡和披萨，终于是体会到了一把日常吃食生活，倒不是想吃这些，而是觉着这种节奏可能就是到了盐湖城常有的情况，体验一把。 坐着吃的时候，旁边来了老爷爷老奶奶，大约都是80+的年纪，起身都需要扶着支撑下的那种，一人拿着一个热狗和一大杯百事可乐，很开心。然后我就想着多次劝解和可乐吃汉堡无果的爸妈。嗨吖。 晚上的时候和姨父聊了会儿，给了许多中肯的建议，以后手术什么的情况，听他们又说了些这些年的一些经历。果然和长辈交谈聊天总是能收获很多，明天还要麻烦他们一大早起来送我去机场，十分感谢。 七年前那会在宜春，第一次见到了姨父姨妈，临行前和表姐约下 C U in America. 然后，这会儿就来了，并没有十分刻意的朝着这块计划，也许这就是一些玄学的事情。:) 宜春每到一个新的地方找房子总是一个很麻烦也很重要的事情。这几年在外面工作，从实习最开始随便凑合，中途和ACE合租大房子，深圳看到同学住处之后愤然带着他换地方，到现在基本定着自如住，经历过这么多好坏的变化，个人觉着租房需要慎重决定。就像最开始公司某个美女原画说的一样，别的地方也花不了太多，住就让自己住的舒服些。宅男表示很赞同。 就一直拖呀拖，然后就在昨天下午，看到几个月前加的群里有人问租房消息，聊了几句之后发现对方竟然就是宜春人，而且位置不错，价格正好是预算理想范围，那就真滴是一拍即合毫不犹豫直接屁颠屁颠的叫他老哥了。 人嘛，该卖屁股的时候就要卖，趁还卖的出去的时候。 这个世界是又多小呀，又碰到了宜春人，不像是北上广这样的大城市，宜春那么小的地方。就像伯伯伯母，姨父姨妈都这么跟我说过，在这这么久了，第一次接待从宜春来的人。哈哈，盐湖城那还有个小哥也是宜春人呀。 缘，妙不可言。 莫以宜春远，江山多胜游。 最后Hello The U!","link":"/New Start/"}],"tags":[{"name":"Entertainment Arts Engineering","slug":"Entertainment-Arts-Engineering","link":"/tags/Entertainment-Arts-Engineering/"},{"name":"游记","slug":"游记","link":"/tags/游记/"},{"name":"随笔","slug":"随笔","link":"/tags/随笔/"},{"name":"Graphics","slug":"Graphics","link":"/tags/Graphics/"},{"name":"C++","slug":"C","link":"/tags/C/"},{"name":"Lua","slug":"Lua","link":"/tags/Lua/"},{"name":"EAE 6320","slug":"EAE-6320","link":"/tags/EAE-6320/"},{"name":"Threads","slug":"Threads","link":"/tags/Threads/"},{"name":"Binary","slug":"Binary","link":"/tags/Binary/"},{"name":"Shader","slug":"Shader","link":"/tags/Shader/"},{"name":"Maya","slug":"Maya","link":"/tags/Maya/"},{"name":"FBX","slug":"FBX","link":"/tags/FBX/"},{"name":"Animation","slug":"Animation","link":"/tags/Animation/"},{"name":"Texture","slug":"Texture","link":"/tags/Texture/"},{"name":"Realtime Rendering","slug":"Realtime-Rendering","link":"/tags/Realtime-Rendering/"},{"name":"EAE 6900","slug":"EAE-6900","link":"/tags/EAE-6900/"},{"name":"Materials","slug":"Materials","link":"/tags/Materials/"},{"name":"Textrure","slug":"Textrure","link":"/tags/Textrure/"},{"name":"Unity","slug":"Unity","link":"/tags/Unity/"},{"name":"xLua","slug":"xLua","link":"/tags/xLua/"},{"name":"AssetBundle","slug":"AssetBundle","link":"/tags/AssetBundle/"},{"name":"Unity Assets Type","slug":"Unity-Assets-Type","link":"/tags/Unity-Assets-Type/"},{"name":"Camera","slug":"Camera","link":"/tags/Camera/"},{"name":"Transforms","slug":"Transforms","link":"/tags/Transforms/"},{"name":"Animator Controller","slug":"Animator-Controller","link":"/tags/Animator-Controller/"},{"name":"OpenFrameworks","slug":"OpenFrameworks","link":"/tags/OpenFrameworks/"},{"name":"Game AI","slug":"Game-AI","link":"/tags/Game-AI/"}],"categories":[{"name":"中文博客","slug":"中文博客","link":"/categories/中文博客/"},{"name":"Game Engine","slug":"Game-Engine","link":"/categories/Game-Engine/"},{"name":"游而远行","slug":"中文博客/游而远行","link":"/categories/中文博客/游而远行/"},{"name":"2018·暑期","slug":"中文博客/2018·暑期","link":"/categories/中文博客/2018·暑期/"},{"name":"Realtime Rendering","slug":"Game-Engine/Realtime-Rendering","link":"/categories/Game-Engine/Realtime-Rendering/"},{"name":"Unity","slug":"Unity","link":"/categories/Unity/"},{"name":"Shader","slug":"Game-Engine/Realtime-Rendering/Shader","link":"/categories/Game-Engine/Realtime-Rendering/Shader/"},{"name":"Hotfix xLua","slug":"Unity/Hotfix-xLua","link":"/categories/Unity/Hotfix-xLua/"},{"name":"Game AI","slug":"Game-AI","link":"/categories/Game-AI/"},{"name":"EAE 6900 - 023","slug":"Game-AI/EAE-6900-023","link":"/categories/Game-AI/EAE-6900-023/"}]}